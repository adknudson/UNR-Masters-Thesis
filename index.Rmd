--- 
title: "Thesis"
author: "Alexander Knudson"
date: "`r format(Sys.Date(), '%A %B %d, %Y')`"
site: bookdown::bookdown_site
documentclass: article
link-citations: yes
github-repo: adkudson/thesis
---

# Preface {-}

In this collection, I will be building a narrative around general linear models as I take an experiment in psychometrics and perform a complete analysis from the ground up.

## Ideas {-}

- Introduce the data
- classical regression
- Bayesian regression
- Choice of priors
- Standardization
- Multilevel modeling
  - Robustness
  - Flexibility
  - Performance
- Pooling
  - no pooling
  - partial pooling
  - complete pooling
- Adaptive regularization
- Residual analysis
- Predictive inference
- Using bigsimr to simulate data sets


# Introduction {-}

TRAMM/bigsimr 70/30 split

**Big Idea:** _making contributions to & gaining mastery of state of the art statistical computing tools and Bayesian modeling/probabilistic programming._

- Acknowledgments
- Motivating Data
  - Pyschometrics
  - Theory and background
  - Research questions
- Classical approaches
  - shortcomings
  - why abandon them
- Bayesian Modeling
  - Mathematical foundations
    - Bayes rule in regression setting
  - Easy in theory, difficult in practice
    - Example of a conjugate priors
    - need more complexity -> computer methods
  - Computer methods needed
- Multilevel Models
  - Types of Pooling
    - No pooling
    - Complete Pooling
    - Partial Pooling
  - Statistical inference
  - Possibility of conjugacy for sigmoid model
  - Sampling
    - Fitting and Diagnostics
    - Incorporate paper *Statistical Software*
    - Stan / BRMS / rstanarm / rethinking
    - Greta (TensorFlow)
    - Pyro / NumPyro (Jax)
    - Model fitting diagnostics
      - $\hat{R}$
      - divergences
- Feature Engineering and Prior Specification
  - Standardizing Predictors
  - Parameterization of the linear predictor
    - Choice of Link Function
    - Choice of Priors
    - lapse rates
- Residual analysis (Goodness of fit and model selection)
  - difference between observed and fitted value (errors)
  - should be normally distributed
  - Heteroskedacity
  - contrast these classic analyses to Bayesian techniques
    - prior and posterior checks
    - LOO
    - cross validation
- Model Checking and Experimental Design Through Synthetic Data
  - The problem of simulating multivariate data with arbitrary marginal distributions
  - Copula approach
    - Nonlinear transformation that invalidates the correlation structure
  - Kendall and Spearman matching
    - Nearest Positive Semidefinite correlation matrix
      - Semidefinte Programming (ProxSDP.jl)
      - https://arxiv.org/abs/1810.05231
      - Qi and Sun 2006 (quadratically convergent method)
  - Pearson matching
    - Chen 2001 (NORTARA)
    - Xiao, Zhou 2019 (Numeric Approximation)
  - Using synthetic data to design experiments
    - Bayesian p-value
    - How much data to notice an effect
    - Bayesian hypothesis testing via predictive performance
- Predictive Inference
  - Compare to conjugate model
  - Prior predictive distributions
  - Posterior predictive distributions
  - Calibrating the model
  - Use of synthetic data to assess model properties
- Discussion
- Conclusion and Future Directions
- References
- Appendix A (Notation)
- Appendix B (Proofs) maybe?


- Orphaned thoughts
  - statistical workflows and reproducible analyses
  - using conda and git
