% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
]{article}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\hypersetup{
  pdftitle={Contributions to Modern Bayesian Multilevel Modeling},
  pdfauthor={Alexander Knudson},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}
\urlstyle{same} % disable monospaced font for URLs
\usepackage{longtable,booktabs}
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx,grffile}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}
\usepackage[]{natbib}
\bibliographystyle{agsm}

\title{Contributions to Modern Bayesian Multilevel Modeling}
\author{Alexander Knudson}
\date{Wednesday July 15, 2020}

\begin{document}
\maketitle

{
\setcounter{tocdepth}{3}
\tableofcontents
}
\hypertarget{abstract}{%
\section*{Abstract}\label{abstract}}


\textbf{Big Idea:} \emph{making contributions to \& gaining mastery of state of the art statistical computing tools and Bayesian modeling/probabilistic programming.}

\hypertarget{acknowledgments}{%
\section*{Acknowledgments}\label{acknowledgments}}


\hypertarget{list-of-tables}{%
\section*{List of Tables}\label{list-of-tables}}


\hypertarget{list-of-figures}{%
\section*{List of Figures}\label{list-of-figures}}


\hypertarget{introduction}{%
\section{Introduction}\label{introduction}}

\begin{itemize}
\tightlist
\item
  Soft intro to modern computing, analysis

  \begin{itemize}
  \tightlist
  \item
    advance in CPU+programming leads to evolved statistical methods

    \begin{itemize}
    \tightlist
    \item
      ML/DL, high dimensional analysis, big data, Bayesian techniques
    \end{itemize}
  \item
    multidisciplinary techniques; numerical methods, probability theory, statistics, computer science, visualizations, etc

    \begin{itemize}
    \tightlist
    \item
      root finding, change of variables, Gaussian quadrature, Hermite polynomials, Monte Carlo simulation, floating point arithmetic
    \end{itemize}
  \item
    Organization and reproducibility are crucial in a data analysis setting

    \begin{itemize}
    \tightlist
    \item
      pre-planning, modularity, workflows, versioning, virtual environments, DRY programming, code that is easy to read
    \end{itemize}
  \item
    Clean data is important for good modeling

    \begin{itemize}
    \tightlist
    \item
      garbage in leads to garbage out
    \end{itemize}
  \end{itemize}
\end{itemize}

With the advances in computational power and high-level programming languages like Python, R, and Julia, statistical methods have evolved to be more flexible and expressive.

\begin{itemize}
\tightlist
\item
  Overview of classical modeling methods

  \begin{itemize}
  \tightlist
  \item
    classical approaches to data analysis usually adhere to the flexibility-interpretability trade-off
  \item
    generally inflexible (parametric) to be more interpretable and computationally easier
  \item
    sometimes a model is too flexible (non-parametric) and loses crucial inferential power
  \item
    sometimes our assumptions about the data are invalid

    \begin{itemize}
    \tightlist
    \item
      normality, independence, heteroskedacity, etc.
    \end{itemize}
  \item
    often limited when it comes to statistical summaries and confidence intervals
  \end{itemize}
\item
  Solutions or alternatives when classical models fail

  \begin{itemize}
  \tightlist
  \item
    Bayesian inference is a powerful, descriptive, and flexible modeling framework
  \item
    Bayes theorem is a simple model of incorporating prior information and data to produce a posterior probability or distribution
  \item
    \(P(\theta | X) \propto P(X | \theta) * P(\theta)\) or \(posterior \propto prior \times likelihood\)

    \begin{itemize}
    \tightlist
    \item
      The prior is some distribution over the parameter space
    \item
      The likelihood is the probability of an outcome in the sample space given a value in the parameter space
    \item
      The posterior is the likelihood of values in the parameter space after observing values from the sample space
    \end{itemize}
  \item
    Bayesian statistics, when described without math, actually feels natural to most people

    \begin{itemize}
    \tightlist
    \item
      you hear hoof beats, you think horses, not zebras {[}unless you're in Africa, but that's prior information ;){]}
    \end{itemize}
  \item
    The catch is that the model is not complete as written above
  \item
    There is actually a denominator in Bayes' Theorem

    \begin{itemize}
    \tightlist
    \item
      \(P(\theta | X) = \frac{P(X | \theta)\cdot P(\theta)}{\sum_i P(X | \theta_i)} = \frac{P(X | \theta)\cdot P(\theta)}{\int_\Omega P(X | \theta)d\theta}\)
    \item
      In general, the denominator is not known, or is not not easy (or possible) to calculate, but it always evaluates to a constant (hence the ``proportional to'')
    \item
      The denominator acts as a scaling value that forces \(P(\theta|X)\) to be a probability distribution (i.e.~area under PDF is equal to 1)
    \item
      There are simulation-based techniques that let one approximate the posterior distribution without needing to know the analytic solution to the denominator
    \end{itemize}
  \end{itemize}
\end{itemize}

I have organized this thesis as follows. In \protect\hyperlink{motivating-data}{Chapter 2} I introduce the data set that drives the narrative and that motivates the adoption of Bayesian multilevel modeling. In \protect\hyperlink{classical-approaches}{Chapter 3} there is a review of classical approaches to modeling with psychometric data, and the benefits and drawbacks of such techniques. \protect\hyperlink{bayesian-modeling}{Chapter 4} introduces Bayesian modeling and programming frameworks for Bayesian inference. In Chapters \protect\hyperlink{multilevel-models}{5} and \protect\hyperlink{feature-engineering}{6} I describe and work through a principled Bayesian workflow for multilevel modeling. Chapters \protect\hyperlink{residual-analysis}{7} and \protect\hyperlink{model-checking}{8} go into more depth on checking the model goodness of fit and model diagnostics in a Bayesian setting. Finally in \protect\hyperlink{predictive-inference}{Chapter 9} I demonstrate how to use the Bayesian model from the principled workflow for predictive inference, and generate multivariate synthetic data via Gaussian copulas.

\hypertarget{motivating-data}{%
\section{Motivating Data}\label{motivating-data}}

\begin{itemize}
\item
  Pyschometrics
\item
  Theory and background
\item
  Research questions
\item
  Psychometric Experiments

  \begin{itemize}
  \tightlist
  \item
    ``The psychometric function relates an observer's performance to an independent variable, usually some physical quantity of a stimulus in a psychophysical task'' \citep{wichmann2001a}
  \item
    Perceptual Synchrony

    \begin{itemize}
    \tightlist
    \item
      Our experiences in life as we age shape the mechanisms of processing multisensory signals
    \item
      Compensation for small temporal differences is beneficial for coherent multisensory experiences, particularly in visual-speech synthesis
    \item
      This gives rise to an idea of the temporal binding window, or the temporal differences for which sensory signals are integrated into a global percept
    \item
      Perceptual synchrony has been previously studied through the point of subjective simultaneity, the physical temporal delay between two signals at which an observer is unsure about their temporal order \citep{stone2001now}
    \end{itemize}
  \item
    Temporal Sensitivity

    \begin{itemize}
    \tightlist
    \item
      The temporal binding window is the time span over which sensory signals arising from different modalities appear integrated into a global percept
    \item
      A deficit in temporal sensitivity may lead to a widening of the temporal binding window and cause reduce the ability to segregate unrelated sensory signals
    \item
      In temporal order judgment tasks, the ability to discriminate the timing of multiple sensory signals is referred to as temporal sensitivity, and is studied through the measurement of the just noticeable difference
    \item
      The just noticeable difference is the smallest lapse in time so that a temporal order can just be determined
    \end{itemize}
  \item
    Temporal Recalibration
  \end{itemize}
\item
  Current Techniques

  \begin{itemize}
  \tightlist
  \item
    Maximum likelihood estimation
  \item
    Bootstrapping for confidence intervals
  \item
    Non-parametric
  \end{itemize}
\item
  Data Collection

  \begin{itemize}
  \tightlist
  \item
    Order of trials
  \item
    The manuscript provided by Ally will really be the main source of content for this section
  \item
    She describes the data collection for three of the sensory tasks
  \end{itemize}
\end{itemize}

\hypertarget{notation}{%
\subsection{Notation}\label{notation}}

We adopt the notation put forth in the book \emph{Data Analysis using Regression and Multilevel/Hierarchical Models} \citep{gelman2006data}, specifically

\begin{itemize}
\tightlist
\item
  Units \(i = 1, \ldots, n\), where \emph{units} are the smallest items of measurements (a single record)
\item
  Outcome measurements \(y = (y_1, \ldots, y_n)\) are the unit-level data being modeled
\item
  Groups \(j = 1, \ldots, J\) for the age level of grouping
\item
  Subjects \(k = 1, \ldots, K\) for the subject level of grouping (since subjects will have multiple units of measurement)
\item
  Index variables \(j[i]\) and \(k[i]\) to code the group and subject membership. For example, if \(j[35]=3\), then the \(35^{th}\) unit in the data belongs to the third age group.
\item
  Coefficients are written with \(\alpha\), \(\beta\), and sometimes \(\gamma\)
\item
  We make our code more readable by typing \(\alpha\), \(\beta\), \(\gamma\) as \texttt{a}, \texttt{b}, \texttt{g}
\item
  Standard deviation is \(\sigma_y\) for data-level errors and \(\sigma_\alpha\), \(\sigma_\beta\), and so forth, for group-level errors
\end{itemize}

\hypertarget{classical-approaches}{%
\section{Classical Approaches}\label{classical-approaches}}

\begin{itemize}
\tightlist
\item
  shortcomings
\item
  why abandon them
\end{itemize}

\hypertarget{bayesian-modeling}{%
\section{Bayesian Modeling}\label{bayesian-modeling}}

\begin{itemize}
\tightlist
\item
  Mathematical foundations

  \begin{itemize}
  \tightlist
  \item
    Bayes rule in regression setting
  \end{itemize}
\item
  Easy in theory, difficult in practice

  \begin{itemize}
  \tightlist
  \item
    Example of a conjugate priors
  \item
    need more complexity -\textgreater{} computer methods
  \end{itemize}
\item
  Computer methods needed
\end{itemize}

\hypertarget{multilevel-models}{%
\section{Multilevel Models}\label{multilevel-models}}

\begin{itemize}
\tightlist
\item
  Types of Pooling

  \begin{itemize}
  \tightlist
  \item
    No pooling
  \item
    Complete Pooling
  \item
    Partial Pooling
  \end{itemize}
\item
  Statistical inference
\item
  Possibility of conjugacy for sigmoid model
\item
  Sampling

  \begin{itemize}
  \tightlist
  \item
    Fitting and Diagnostics
  \item
    Incorporate paper \emph{Statistical Software}
  \item
    Stan / BRMS / rstanarm / rethinking
  \item
    Greta (TensorFlow)
  \item
    Pyro / NumPyro (Jax)
  \item
    Model fitting diagnostics

    \begin{itemize}
    \tightlist
    \item
      \(\hat{R}\)
    \item
      divergences
    \end{itemize}
  \end{itemize}
\end{itemize}

\hypertarget{feature-engineering}{%
\section{Feature Engineering and Prior Specification}\label{feature-engineering}}

\begin{itemize}
\tightlist
\item
  Standardizing Predictors
\item
  Parameterization of the linear predictor

  \begin{itemize}
  \tightlist
  \item
    Choice of Link Function
  \item
    Choice of Priors
  \item
    lapse rates
  \end{itemize}
\end{itemize}

\hypertarget{residual-analysis}{%
\section{Residual Analysis}\label{residual-analysis}}

\begin{itemize}
\tightlist
\item
  difference between observed and fitted value (errors)
\item
  should be normally distributed
\item
  Heteroskedacity
\item
  contrast these classic analyses to Bayesian techniques

  \begin{itemize}
  \tightlist
  \item
    prior and posterior checks
  \item
    LOO
  \item
    cross validation
  \end{itemize}
\end{itemize}

\hypertarget{model-checking}{%
\section{Model Checking}\label{model-checking}}

\begin{itemize}
\tightlist
\item
  The problem of simulating multivariate data with arbitrary marginal distributions
\item
  Copula approach

  \begin{itemize}
  \tightlist
  \item
    Nonlinear transformation that invalidates the correlation structure
  \end{itemize}
\item
  Kendall and Spearman matching

  \begin{itemize}
  \tightlist
  \item
    Nearest Positive Semidefinite correlation matrix

    \begin{itemize}
    \tightlist
    \item
      Semidefinte Programming (ProxSDP.jl)
    \item
      \url{https://arxiv.org/abs/1810.05231}
    \item
      Qi and Sun 2006 (quadratically convergent method)
    \end{itemize}
  \end{itemize}
\item
  Pearson matching

  \begin{itemize}
  \tightlist
  \item
    Chen 2001 (NORTARA)
  \item
    Xiao, Zhou 2019 (Numeric Approximation)
  \end{itemize}
\item
  Using synthetic data to design experiments

  \begin{itemize}
  \tightlist
  \item
    Bayesian p-value
  \item
    How much data to notice an effect
  \item
    Bayesian hypothesis testing via predictive performance
  \end{itemize}
\end{itemize}

\hypertarget{predictive-inference}{%
\section{Predictive Inference}\label{predictive-inference}}

\begin{itemize}
\tightlist
\item
  Compare to conjugate model
\item
  Prior predictive distributions
\item
  Posterior predictive distributions
\item
  Calibrating the model
\item
  Use of synthetic data to assess model properties
\end{itemize}

\hypertarget{discussion}{%
\section{Discussion}\label{discussion}}

Really just placeholder stuff for now.

\[
\frac{1}{\sqrt{2\pi\sigma}} \exp{\left\lbrace \frac{(x-\mu)^2}{\sigma^2} \right\rbrace}
\]

\hypertarget{conclusion}{%
\section{Conclusion}\label{conclusion}}

Really just placeholder stuff for now.

\[
\frac{1}{\sqrt{2\pi\sigma}} \exp{\left\lbrace \frac{(x-\mu)^2}{\sigma^2} \right\rbrace}
\]

\hypertarget{appendix-a}{%
\section*{Appendix A}\label{appendix-a}}


\hypertarget{appendix-b}{%
\section*{Appendix B}\label{appendix-b}}


  \bibliography{bibliography.bib}

\end{document}
