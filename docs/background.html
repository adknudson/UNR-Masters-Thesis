<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>3 Background to Modeling | Contributions to Modern Bayesian Multilevel Modeling</title>
  <meta name="description" content="3 Background to Modeling | Contributions to Modern Bayesian Multilevel Modeling" />
  <meta name="generator" content="bookdown 0.20 and GitBook 2.6.7" />

  <meta property="og:title" content="3 Background to Modeling | Contributions to Modern Bayesian Multilevel Modeling" />
  <meta property="og:type" content="book" />
  
  
  
  <meta name="github-repo" content="adkudson/thesis" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="3 Background to Modeling | Contributions to Modern Bayesian Multilevel Modeling" />
  
  
  

<meta name="author" content="Alexander Knudson" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="motivating-data.html"/>
<link rel="next" href="bayesian-modeling.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />


<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introduction</a></li>
<li class="chapter" data-level="2" data-path="motivating-data.html"><a href="motivating-data.html"><i class="fa fa-check"></i><b>2</b> Background and Motivating Data</a><ul>
<li class="chapter" data-level="2.1" data-path="motivating-data.html"><a href="motivating-data.html#psycho-experiments"><i class="fa fa-check"></i><b>2.1</b> Psychometric Experiments</a></li>
<li class="chapter" data-level="2.2" data-path="motivating-data.html"><a href="motivating-data.html#toj-task"><i class="fa fa-check"></i><b>2.2</b> Temporal Order Judgment Data</a></li>
<li class="chapter" data-level="2.3" data-path="motivating-data.html"><a href="motivating-data.html#data-visualizations-and-quirks"><i class="fa fa-check"></i><b>2.3</b> Data Visualizations and Quirks</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="background.html"><a href="background.html"><i class="fa fa-check"></i><b>3</b> Background to Modeling</a></li>
<li class="chapter" data-level="4" data-path="bayesian-modeling.html"><a href="bayesian-modeling.html"><i class="fa fa-check"></i><b>4</b> Bayesian Multilevel Modeling</a><ul>
<li class="chapter" data-level="4.1" data-path="bayesian-modeling.html"><a href="bayesian-modeling.html#bayesian-stuff"><i class="fa fa-check"></i><b>4.1</b> Bayesian Stuff</a></li>
<li class="chapter" data-level="4.2" data-path="bayesian-modeling.html"><a href="bayesian-modeling.html#multilevel-modeling-stuff"><i class="fa fa-check"></i><b>4.2</b> Multilevel Modeling Stuff</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="workflow.html"><a href="workflow.html"><i class="fa fa-check"></i><b>5</b> Principled Bayesian Workflow</a><ul>
<li class="chapter" data-level="5.1" data-path="workflow.html"><a href="workflow.html#iter1"><i class="fa fa-check"></i><b>5.1</b> Iteration 1 (The Journey of a Thousand Miles Begins with a Single Step)</a><ul>
<li class="chapter" data-level="5.1.1" data-path="workflow.html"><a href="workflow.html#pre-model-pre-data"><i class="fa fa-check"></i><b>5.1.1</b> Pre-Model, Pre-Data</a></li>
<li class="chapter" data-level="5.1.2" data-path="workflow.html"><a href="workflow.html#post-model-pre-data"><i class="fa fa-check"></i><b>5.1.2</b> Post-Model, Pre-Data</a></li>
<li class="chapter" data-level="5.1.3" data-path="workflow.html"><a href="workflow.html#post-model-post-data"><i class="fa fa-check"></i><b>5.1.3</b> Post-Model, Post-Data</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="workflow.html"><a href="workflow.html#iter2"><i class="fa fa-check"></i><b>5.2</b> Iteration 2 (Electric Boogaloo)</a><ul>
<li class="chapter" data-level="5.2.1" data-path="workflow.html"><a href="workflow.html#iter2-model-dev"><i class="fa fa-check"></i><b>5.2.1</b> Model Development</a></li>
<li class="chapter" data-level="5.2.2" data-path="workflow.html"><a href="workflow.html#iter2-sim"><i class="fa fa-check"></i><b>5.2.2</b> Simulate bayesian ensemble</a></li>
<li class="chapter" data-level="5.2.3" data-path="workflow.html"><a href="workflow.html#iter2-prior-check"><i class="fa fa-check"></i><b>5.2.3</b> Prior Checks</a></li>
<li class="chapter" data-level="5.2.4" data-path="workflow.html"><a href="workflow.html#iter2-config-algo"><i class="fa fa-check"></i><b>5.2.4</b> Configure algorithm</a></li>
<li class="chapter" data-level="5.2.5" data-path="workflow.html"><a href="workflow.html#iter2-fit-sim"><i class="fa fa-check"></i><b>5.2.5</b> Fit simulated ensemble</a></li>
<li class="chapter" data-level="5.2.6" data-path="workflow.html"><a href="workflow.html#iter2-algo-calibration"><i class="fa fa-check"></i><b>5.2.6</b> Algorithmic calibration</a></li>
<li class="chapter" data-level="5.2.7" data-path="workflow.html"><a href="workflow.html#iter2-inferential-calibration"><i class="fa fa-check"></i><b>5.2.7</b> Inferential Calibration</a></li>
<li class="chapter" data-level="5.2.8" data-path="workflow.html"><a href="workflow.html#iter2-fit-obs"><i class="fa fa-check"></i><b>5.2.8</b> Fit Observation</a></li>
<li class="chapter" data-level="5.2.9" data-path="workflow.html"><a href="workflow.html#iter2-diagnose-post"><i class="fa fa-check"></i><b>5.2.9</b> Diagnose posterior fit</a></li>
<li class="chapter" data-level="5.2.10" data-path="workflow.html"><a href="workflow.html#iter2-post-retro"><i class="fa fa-check"></i><b>5.2.10</b> Posterior retrodictive checks</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="workflow.html"><a href="workflow.html#iter3"><i class="fa fa-check"></i><b>5.3</b> Iteration 3 (The one for Me)</a><ul>
<li class="chapter" data-level="5.3.1" data-path="workflow.html"><a href="workflow.html#iter3-model-dev"><i class="fa fa-check"></i><b>5.3.1</b> Model Development</a></li>
<li class="chapter" data-level="5.3.2" data-path="workflow.html"><a href="workflow.html#iter3-diagnose-post"><i class="fa fa-check"></i><b>5.3.2</b> Diagnose posterior fit</a></li>
<li class="chapter" data-level="5.3.3" data-path="workflow.html"><a href="workflow.html#iter3-post-retro"><i class="fa fa-check"></i><b>5.3.3</b> Posterior retrodictive checks</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="workflow.html"><a href="workflow.html#iter4"><i class="fa fa-check"></i><b>5.4</b> Iteration 4 (What’s one more?)</a><ul>
<li class="chapter" data-level="5.4.1" data-path="workflow.html"><a href="workflow.html#iter4-conceptual"><i class="fa fa-check"></i><b>5.4.1</b> Conceptual analysis</a></li>
<li class="chapter" data-level="5.4.2" data-path="workflow.html"><a href="workflow.html#iter4-summary-stats"><i class="fa fa-check"></i><b>5.4.2</b> Construct summary statistics</a></li>
<li class="chapter" data-level="5.4.3" data-path="workflow.html"><a href="workflow.html#iter4-model-dev"><i class="fa fa-check"></i><b>5.4.3</b> Model Development</a></li>
<li class="chapter" data-level="5.4.4" data-path="workflow.html"><a href="workflow.html#iter4-fit-obs"><i class="fa fa-check"></i><b>5.4.4</b> Fit the model</a></li>
<li class="chapter" data-level="5.4.5" data-path="workflow.html"><a href="workflow.html#iter4-post-retro"><i class="fa fa-check"></i><b>5.4.5</b> Posterior retrodictive checks</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="model-checking.html"><a href="model-checking.html"><i class="fa fa-check"></i><b>6</b> Model Checking</a><ul>
<li class="chapter" data-level="6.1" data-path="model-checking.html"><a href="model-checking.html#section"><i class="fa fa-check"></i><b>6.1</b> </a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="predictive-inference.html"><a href="predictive-inference.html"><i class="fa fa-check"></i><b>7</b> Predictive Inference</a></li>
<li class="chapter" data-level="8" data-path="results.html"><a href="results.html"><i class="fa fa-check"></i><b>8</b> Results</a></li>
<li class="chapter" data-level="9" data-path="discussion.html"><a href="discussion.html"><i class="fa fa-check"></i><b>9</b> Discussion</a></li>
<li class="chapter" data-level="10" data-path="conclusion.html"><a href="conclusion.html"><i class="fa fa-check"></i><b>10</b> Conclusion</a></li>
<li class="appendix"><span><b>Appendix</b></span></li>
<li class="chapter" data-level="A" data-path="supplementary-code.html"><a href="supplementary-code.html"><i class="fa fa-check"></i><b>A</b> Supplementary Code</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Contributions to Modern Bayesian Multilevel Modeling</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="background" class="section level1">
<h1><span class="header-section-number">3</span> Background to Modeling</h1>
<p>A psychometric function can be fit using a generalized linear model (GLM) with the link function coming from the family of S-shaped curves called a sigmoid. Commonly GLMs are fit using maximum likelihood estimation (MLE). In the case of a psychometric experiment, we can represent the outcome of a single trial as the result of a random experiment arising from a Bernoulli process. Without loss of generality, the psychometric function, <span class="math inline">\(F(x; \theta)\)</span>, determines the probability that the outcome is 1.</p>
<p><span class="math display">\[\begin{align*}
Y &amp;\sim \textrm{Bernoulli}(\pi) \\
\pi &amp;= P(Y=1 \vert x; \theta) = F(x; \theta)
\end{align*}\]</span></p>
<p>If <span class="math inline">\(P(Y=1 | x; \theta) = F(x;\theta)\)</span>, then <span class="math inline">\(P(Y = 0 | x; \theta) = 1 - F(x;\theta)\)</span>, and hence the probability of an outcome is</p>
<p><span class="math display" id="eq:bernproby">\[\begin{equation}
  P(Y=y | x; \theta) = F(x;\theta)^y(1-F(x;\theta))^{1-y}
  \tag{3.1}
\end{equation}\]</span></p>
<p>The likelihood function, <span class="math inline">\(\mathcal{L}\)</span>, can be determined using equation <a href="background.html#eq:bernproby">(3.1)</a></p>
<p><span class="math display" id="eq:bernlik">\[\begin{equation}
  \begin{split}
    \mathcal{L}(\theta | y, x) &amp;= \prod_{i}^{N} P(y_i | x_i; \theta) \\
    &amp;= \prod_{i}^{N}F(x_i;\theta)^{y_i}(1-F(x_i;\theta))^{1-y_i}
  \end{split}
  \tag{3.2}
\end{equation}\]</span></p>
<p>Equation <a href="background.html#eq:bernlik">(3.2)</a> is commonly expressed in terms of its logarithm.</p>
<p><span class="math display" id="eq:bernloglik">\[\begin{equation}
  \ln \mathcal{L}(\theta | y, x) = \sum_{i}^{N} y_i \ln\left(F(x_i;\theta)\right) + (1-y_i) \ln\left(F(x_i;\theta))\right)
  \tag{3.3}
\end{equation}\]</span></p>
<p>From here the classical approach would be to take the derivative of <a href="background.html#eq:bernloglik">(3.3)</a>, set it equal to <span class="math inline">\(0\)</span>, and solve for <span class="math inline">\(\theta\)</span>. Additionally one might perform a second derivative test to ensure that the solution is indeed a maximizer to <a href="background.html#eq:bernloglik">(3.3)</a> (and hence to <a href="background.html#eq:bernlik">(3.2)</a>). However no closed form expression exists for the solution to <span class="math inline">\(\frac{d}{d\theta} \ln \mathcal{L}(\theta) = 0\)</span>, and so numerical optimization methods like gradient descent are used to iteratively find the MLE solution. In most cases this works fine, but there are common situations where MLE fails. In this chapter I will discuss common techniques for fitting psychometric functions, the reasons to use these methods, and the conditions for when they are not optimal.</p>
<p>As introduced above, the first method is to use generalized linear models. A GLM is one that can be transformed into a linear model via a link function. An example of this is the logistic function which takes <span class="math inline">\(x \in \mathbb{R}\)</span> and squishes the output to be in <span class="math inline">\((0, 1)\)</span>.</p>
<p><span class="math display" id="eq:logistic">\[\begin{equation}
  F(\theta) = \frac{1}{1 + \exp\left(-\theta\right)}
  \tag{3.4}
\end{equation}\]</span></p>
<p>Since <span class="math inline">\(F\)</span> is a strictly increasing and continuous function, it has an inverse, and the link for <a href="background.html#eq:logistic">(3.4)</a> is the log-odds or logit function.</p>
<p><span class="math display" id="eq:logit">\[\begin{equation}
  F^{-1}(\pi) = \mathrm{logit}(\pi) = \ln\left(\frac{\pi}{1 - \pi}\right)
  \tag{3.5}
\end{equation}\]</span></p>
<p>By taking <span class="math inline">\((F^{-1} \circ F)(\theta)\)</span> we can arrive at a relationship that is linear in <span class="math inline">\(\theta\)</span>.</p>
<p><span class="math display">\[\begin{align*}
  \pi = F(\theta) \Longleftrightarrow F^{-1}(\pi) &amp;= F^{-1}(F(\theta)) \\
  &amp; = \ln\left(\frac{F(\theta)}{1 - F(\theta)}\right) \\
  &amp;= \ln(F(\theta)) - \ln(1 - F(\theta)) \\
  &amp;= \ln\left(\frac{1}{1 + \exp(-\theta)}\right) - \ln\left(\frac{\exp(-\theta)}{1 + \exp(-\theta)}\right) \\
  &amp;= - \ln(1 + \exp(-\theta)) - \ln(\exp(-\theta)) + \ln(1 + \exp(-\theta)) \\
  &amp;= - \ln(\exp(-\theta)) \\
  &amp;= \theta
\end{align*}\]</span></p>
<p>Linear models are favored in statistics because they are generally easier to interpret than other types of models. For example, say <span class="math inline">\(\mathrm{logit}(\pi) = 0.5 + 1.5x\)</span> where <span class="math inline">\(\pi\)</span> is the probability of a positive outcome, <span class="math inline">\(Y=1\)</span>. We can say that at <span class="math inline">\(x = 0\)</span>, the log-odds of a positive outcome is 0.5, and an increase in <span class="math inline">\(x\)</span> by 1 increases the log-odds by 1.5.</p>
<p>There is nothing that is particular about the logistic function that makes it the only suitable sigmoid for psychometric functions. Other common link functions include the probit (inverse of the standard normal CDF) and Weibull inverse CDF. In fact, any continuous CDF defined on the real number line can be used for psychometric functions. A PF only requires that a function is strictly increasing and bounded between 0 and 1.The logit and probit links have properties such as connections to log-odds and the normal distribution that make working with them more convenient.</p>
<ul>
<li>Generalized Linear Models
<ul>
<li>classical approaches to fitting/estimation
<ul>
<li>Maximum likelihood estimation
<ul>
<li>Simple and almost every piece of statistical software will have an implementation</li>
</ul></li>
</ul></li>
<li>Expectation Maximization</li>
<li>Random effects (Gelmen and Hill)</li>
<li>Bayesian GLMs
<ul>
<li>Completely reliant on MCMC</li>
</ul></li>
</ul></li>
<li>Model-free estimations (footnote? remark?)
<ul>
<li>non-parametric models</li>
<li><span class="citation">(Zchaluk and Foster <a href="#ref-zchaluk2009model" role="doc-biblioref">2009</a>)</span></li>
</ul></li>
<li>Bayesian logistic regression
<ul>
<li><span class="citation">Gelman et al. (<a href="#ref-gelman2008weakly" role="doc-biblioref">2008</a>)</span></li>
<li>Can’t completely express the structure (hierarchy) of the data</li>
</ul></li>
<li>Residual Analysis
<ul>
<li>using the fitted values vs. the observed values to evaluate goodness of fit</li>
<li></li>
</ul></li>
<li>So what’s the answer?
<ul>
<li>The last two options (bayes + multilevel) when on their own do well, but are not robust to</li>
</ul></li>
<li>shortcomings
<ul>
<li>Convergence failure in the presence of complete separation
<ul>
<li><span class="citation">(Prins <a href="#ref-prins2019too" role="doc-biblioref">2019</a>)</span>, <span class="citation">(Ghosh et al. <a href="#ref-ghosh2018use" role="doc-biblioref">2018</a>)</span></li>
<li>Give an example with how the MLE values are estimated</li>
<li>Give an example where MLE fails</li>
</ul></li>
</ul></li>
</ul>

</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-gelman2008weakly">
<p>Gelman, Andrew, Aleks Jakulin, Maria Grazia Pittau, Yu-Sung Su, and others. 2008. “A Weakly Informative Default Prior Distribution for Logistic and Other Regression Models.” <em>The Annals of Applied Statistics</em> 2 (4): 1360–83.</p>
</div>
<div id="ref-ghosh2018use">
<p>Ghosh, Joyee, Yingbo Li, Robin Mitra, and others. 2018. “On the Use of Cauchy Prior Distributions for Bayesian Logistic Regression.” <em>Bayesian Analysis</em> 13 (2): 359–83.</p>
</div>
<div id="ref-prins2019too">
<p>Prins, Nicolaas. 2019. “Too Much Model, Too Little Data: How a Maximum-Likelihood Fit of a Psychometric Function May Fail, and How to Detect and Avoid This.” <em>Attention, Perception, &amp; Psychophysics</em> 81 (5): 1725–39.</p>
</div>
<div id="ref-zchaluk2009model">
<p>Zchaluk, Kamila, and David H Foster. 2009. “Model-Free Estimation of the Psychometric Function.” <em>Attention, Perception, &amp; Psychophysics</em> 71 (6): 1414–25.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="motivating-data.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="bayesian-modeling.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": false,
"twitter": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": null,
"history": {
"link": null,
"text": null
},
"view": {
"link": "https://github.com/adknudson/thesis/blob/master/030-background.Rmd",
"text": null
},
"download": ["adknudson-thesis.pdf"],
"toc": {
"collapse": "section",
"scroll_highlight": true
},
"toc_depth": 3,
"toolbar": {
"position": "fixed"
},
"search": true,
"info": true
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
