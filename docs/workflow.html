<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>3 Principled Bayesian Workflow | Application of a Principaled Bayesian Workflow to Multilevel Modeling</title>
  <meta name="description" content="3 Principled Bayesian Workflow | Application of a Principaled Bayesian Workflow to Multilevel Modeling" />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="3 Principled Bayesian Workflow | Application of a Principaled Bayesian Workflow to Multilevel Modeling" />
  <meta property="og:type" content="book" />
  
  
  
  <meta name="github-repo" content="adkudson/thesis" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="3 Principled Bayesian Workflow | Application of a Principaled Bayesian Workflow to Multilevel Modeling" />
  
  
  

<meta name="author" content="Alexander D. Knudson" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="motivating-data.html"/>
<link rel="next" href="model-checking.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>
<link href="libs/anchor-sections-1.0/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0/anchor-sections.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />


<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#ch010-classical-methods"><i class="fa fa-check"></i><b>1.1</b> Everything can be Blamed on Fisher</a></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#ch010-new-methods"><i class="fa fa-check"></i><b>1.2</b> Proposal of New Methods</a></li>
<li class="chapter" data-level="1.3" data-path="index.html"><a href="index.html#ch010-organization"><i class="fa fa-check"></i><b>1.3</b> Organization</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="motivating-data.html"><a href="motivating-data.html"><i class="fa fa-check"></i><b>2</b> What is a Model without Data</a><ul>
<li class="chapter" data-level="2.1" data-path="motivating-data.html"><a href="motivating-data.html#psycho-experiments"><i class="fa fa-check"></i><b>2.1</b> Psychometric Experiments</a></li>
<li class="chapter" data-level="2.2" data-path="motivating-data.html"><a href="motivating-data.html#toj-task"><i class="fa fa-check"></i><b>2.2</b> Temporal Order Judgment Data</a></li>
<li class="chapter" data-level="2.3" data-path="motivating-data.html"><a href="motivating-data.html#data-visualizations-and-quirks"><i class="fa fa-check"></i><b>2.3</b> Data Visualizations and Quirks</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="workflow.html"><a href="workflow.html"><i class="fa fa-check"></i><b>3</b> Principled Bayesian Workflow</a><ul>
<li class="chapter" data-level="3.1" data-path="workflow.html"><a href="workflow.html#iter1"><i class="fa fa-check"></i><b>3.1</b> Iteration 1 (journey of a thousand miles)</a></li>
<li class="chapter" data-level="3.2" data-path="workflow.html"><a href="workflow.html#iter2"><i class="fa fa-check"></i><b>3.2</b> Iteration 2 (electric boogaloo)</a></li>
<li class="chapter" data-level="3.3" data-path="workflow.html"><a href="workflow.html#iter3"><i class="fa fa-check"></i><b>3.3</b> Iteration 3 (the one for me)</a></li>
<li class="chapter" data-level="3.4" data-path="workflow.html"><a href="workflow.html#iter4"><i class="fa fa-check"></i><b>3.4</b> Iteration 4 (what’s one more)</a></li>
<li class="chapter" data-level="3.5" data-path="workflow.html"><a href="workflow.html#iter5"><i class="fa fa-check"></i><b>3.5</b> Iteration 5 (final_final_draft_2.pdf)</a></li>
<li class="chapter" data-level="3.6" data-path="workflow.html"><a href="workflow.html#celebrate"><i class="fa fa-check"></i><b>3.6</b> Celebrate</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="model-checking.html"><a href="model-checking.html"><i class="fa fa-check"></i><b>4</b> Model Checking</a></li>
<li class="chapter" data-level="5" data-path="predictive-inferences.html"><a href="predictive-inferences.html"><i class="fa fa-check"></i><b>5</b> Predictive Inference</a></li>
<li class="chapter" data-level="6" data-path="results.html"><a href="results.html"><i class="fa fa-check"></i><b>6</b> Psychometric Results</a></li>
<li class="chapter" data-level="7" data-path="discussion.html"><a href="discussion.html"><i class="fa fa-check"></i><b>7</b> Discussion</a></li>
<li class="chapter" data-level="8" data-path="conclusion.html"><a href="conclusion.html"><i class="fa fa-check"></i><b>8</b> Conclusion</a></li>
<li class="appendix"><span><b>Appendix</b></span></li>
<li class="chapter" data-level="A" data-path="supplementary-code.html"><a href="supplementary-code.html"><i class="fa fa-check"></i><b>A</b> Supplementary Code</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Application of a Principaled Bayesian Workflow to Multilevel Modeling</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="workflow" class="section level1">
<h1><span class="header-section-number">3</span> Principled Bayesian Workflow</h1>
<p><em>The meat, the cheese, the entire sandwich</em></p>
<p>Leading up to now, I haven’t discussed what is a principled Bayesian workflow, nor what multilevel modeling is. I was hoping to build up the suspense. Well I hope you’re now ready for the answer. A principled Bayesian workflow is a method of employing domain expertise and statistical knowledge to iteratively build a statistical model that satisfies the constraints and goals set forth by the researcher. Oh, and Bayesian techniques are used in exchange for classical ones. Maybe not worth the suspense, but the simple idea spawns a creative and descriptive way to analyze data.</p>
<p>What about the multilevel aspect? While I get into that more in the following sections, the concept is simple. Multilevel models should be the default. The alternatives are models with complete pooling, or models with no pooling. Pooling vs. no pooling is a fancy way of saying that all the data is modeled as a whole, or the smallest component (group) is modeled individually. The former implies that the variation between groups is zero (all groups are the same), and the latter implies that the variation between groups is infinite (no groups are the same). Multilevel models assume that the truth is somewhere in the middle of zero and infinity. That’s not a difficult thing to posit.</p>
<p>Hierarchical models are a specific kind of multilevel model where one or more groups are nested within a larger one. In the case of the psychometric data, there are three age groups, and within each age group are individual subjects. Multilevel modeling provides a way to quantify and apportion the variation within the data to each level in the model. For an in-depth introduction to multilevel modeling, see <span class="citation">Gelman and Hill (<a href="#ref-gelman2006data" role="doc-biblioref">2006</a>)</span>.</p>
<p>There are many great resources out there for following along with an analysis of some data or problem, and much more is the abundance of tips, tricks, techniques, and testimonies to good modeling practices. The problem is that many of these prescriptions are given without context for when they are appropriate to be taken. According to <span class="citation">Betancourt (<a href="#ref-betancourt2020" role="doc-biblioref">2020</a>)</span>, this leaves “practitioners to piece together their own model building workflows from potentially incomplete or even inconsistent heuristics.” The concept of a principled workflow is that for any given problem, there is not, nor should there be, a default set of steps to take to get from data exploration to predictive inferences. Rather great consideration must be given to domain expertise and the questions that one is trying to answer with the data.</p>
<p>Since everyone asks different questions, the value of a model is not in how well it ticks the boxes of goodness-of-fit checks, but in how consistent it is with domain expertise and its ability to answer the unique set of questions. Betancourt suggests answering four questions to evaluate a model by:</p>
<ol style="list-style-type: decimal">
<li>Domain Expertise Consistency - Is our model consistent with our domain expertise?</li>
<li>Computational Faithfulness - Will our computational tools be sufficient to accurately fit our posteriors?</li>
<li>Inferential Adequacy - Will our inferences provide enough information to answer our questions?</li>
<li>Model Adequacy - Is our model rich enough to capture the relevant structure of the true data generating process?</li>
</ol>
<p>Like any good Bayesian<a href="#fn6" class="footnote-ref" id="fnref6"><sup>6</sup></a>, much work is done before seeing the data or building a model. This may include talking with experts to gain domain knowledge or to <em>elicit priors</em>. Experts may know something about a particular measure, perhaps the mean or variability of the data from years of research, and different experts may provide different estimates of a measure. The benefit of modeling in a Bayesian framework is that all prior knowledge may be incorporated into the model to be used to estimate the <em>posterior distribution</em>. The same prior knowledge may also be used to check the posterior to ensure that predictions remain within physical or expert-given constraints. Consistency is key.</p>
<p>The computational tool I will be using to estimate the posterior is a probabilistic programming language (PPL) called Stan <span class="citation">(Guo et al. <a href="#ref-R-rstan" role="doc-biblioref">2020</a>)</span> within the R programming language. Stan uses the No U-Turn Sampler (NUTS) version of Hamiltonian Monte Carlo (HMC). For a gentle introduction to Bayesian statistics and sampling methods, see <span class="citation">Bolstad and Curran (<a href="#ref-bolstad2016introduction" role="doc-biblioref">2016</a>)</span>, and for an in-depth review of HMC see <span class="citation">Betancourt (<a href="#ref-betancourt2017conceptual" role="doc-biblioref">2017</a>)</span>.</p>
<p>Why do we need a sampler at all? Bayesian statistics and modeling stems from Bayes theorem (Equation <a href="workflow.html#eq:bayesthm">(3.1)</a>). The prior <span class="math inline">\(P(\theta)\)</span> is some distribution over the parameter space and the likelihood <span class="math inline">\(P(X | \theta)\)</span> is the probability of an outcome in the sample space given a value in the parameter space. To keep things simple, we generally say that the posterior is proportional to the prior times the likelihood. Why proportional? The posterior distribution is a probability distribution, which means that the sum or integral over the parameter space must evaluate to one. Because of this constraint, the denominator in <a href="workflow.html#eq:bayesthm">(3.1)</a> acts as a scale factor to ensure that the posterior is valid. Often it happens that the integral in the denominator is complex or of a high dimension. In the former situation, the integral may not be possible to evaluate, and in the latter there may not be enough computational resources in the world to perform a simple grid approximation.</p>
<p><span class="math display" id="eq:bayesthm">\[\begin{equation}
  P(\theta | X) = \frac{P(X | \theta)\cdot P(\theta)}{\sum_i P(X | \theta_i)} =   \frac{P(X | \theta)\cdot P(\theta)}{\int_\Omega P(X | \theta)d\theta}
  \tag{3.1}
\end{equation}\]</span></p>
<p>The solution is to use Markov Chain Monte Carlo (MCMC). The idea is that we can <em>draw samples</em> from the posterior distribution in a way that samples proportionally to the density. This sampling is a form of approximation to the area under the curve (i.e. an approximation to the denominator in <a href="workflow.html#eq:bayesthm">(3.1)</a>). Rejection sampling <span class="citation">(Gilks and Wild <a href="#ref-gilks1992adaptive" role="doc-biblioref">1992</a>)</span> and slice sampling <span class="citation">(Neal <a href="#ref-neal2003slice" role="doc-biblioref">2003</a>)</span> are basic methods for sampling from a target distribution, however they can often be inefficient<a href="#fn7" class="footnote-ref" id="fnref7"><sup>7</sup></a>. NUTS is a much more complex algorithm that can be compared to a physics simulation. A massless “particle” is flicked in a random direction with some amount of kinetic energy in a probability field, and is stopped randomly. The stopping point is the new proposal sample. The No U-Turn part means that when the algorithm detects that the particle is turning around, it will stop so as not to return to the starting position. This sampling scheme has a much higher rate of accepted samples, and also comes with many built-in diagnostic tools that let us know when the sampler is having trouble efficiently exploring the posterior. I’ll talk more about these diagnostic tools throughout the remaining sections and in <a href="model-checking.html#model-checking">chapter 4</a>.</p>
<p>The question of inferential adequacy depends on the set of questions that we are seeking to answer with the data from the psychometric experiment. The broad objective is to determine if there are any significant differences between age groups when it comes to temporal sensitivity, perceptual synchrony, and temporal recalibration, and if the task influences the results as well. The specific goals are to estimate and compare the PSS an JND across all age groups, conditions, and tasks, and determine the affect of recalibration between age groups.</p>
<p>For the last question, model adequacy, I will be following a set of steps proposed in <span class="citation">Betancourt (<a href="#ref-betancourt2020" role="doc-biblioref">2020</a>)</span>. The purpose of laying out these steps is not to again blindly check them off, but to force the analyst to carefully consider each point and make an <em>informed</em> decision whether the step is necessary or to craft the specifics of how the step should be completed. The steps are listed in table <a href="workflow.html#tab:ch030-workflow-steps">3.1</a>. These steps are also not meant to be followed linearly. If at any point it is discovered that there is an issue in conceptual understanding or model adequacy or something else, then it is encouraged to go back to a previous step and start with a new understanding.</p>
<table class="table" style="margin-left: auto; margin-right: auto;">
<caption>
<span id="tab:ch030-workflow-steps">Table 3.1: </span>Principled workflow
</caption>
<thead>
<tr>
<th style="text-align:left;">
Part
</th>
<th style="text-align:left;">
Step
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;vertical-align: top !important;" rowspan="3">
Pre-Model, Pre-Data
</td>
<td style="text-align:left;">
conceptual analysis
</td>
</tr>
<tr>
<td style="text-align:left;">
define observational space
</td>
</tr>
<tr>
<td style="text-align:left;">
construct summary statistics
</td>
</tr>
<tr>
<td style="text-align:left;vertical-align: top !important;" rowspan="8">
Post-Model, Pre-Data
</td>
<td style="text-align:left;">
develop model
</td>
</tr>
<tr>
<td style="text-align:left;">
construct summary functions
</td>
</tr>
<tr>
<td style="text-align:left;">
simulate Bayesian ensemble
</td>
</tr>
<tr>
<td style="text-align:left;">
prior checks
</td>
</tr>
<tr>
<td style="text-align:left;">
configure algorithm
</td>
</tr>
<tr>
<td style="text-align:left;">
fit simulated ensemble
</td>
</tr>
<tr>
<td style="text-align:left;">
algorithmic calibration
</td>
</tr>
<tr>
<td style="text-align:left;">
inferential calibration
</td>
</tr>
<tr>
<td style="text-align:left;vertical-align: top !important;" rowspan="4">
Post-Model, Post-Data
</td>
<td style="text-align:left;">
fit observed data
</td>
</tr>
<tr>
<td style="text-align:left;">
diagnose posterior fit
</td>
</tr>
<tr>
<td style="text-align:left;">
posterior retrodictive checks
</td>
</tr>
<tr>
<td style="text-align:left;">
celebrate
</td>
</tr>
</tbody>
</table>
<p>I’ll talk about each step in the first iteration, but may choose to omit steps in subsequent iterations if there are no changes. For the purposes of building a model and being concise, I will focus around the audiovisual TOJ task in this chapter, but the final model will apply similarly to the visual and duration tasks. For the sensorimotor task, the model will be modified to accept Bernoulli data as apposed to aggregated Binomial counts (described more in the next section).</p>
<div id="iter1" class="section level2">
<h2><span class="header-section-number">3.1</span> Iteration 1 (journey of a thousand miles)</h2>
<p><strong>Pre-Model, Pre-Data</strong></p>
<p>I begin the modeling process by modeling the experiment according to the description of how it occurred and how the data were collected. This first part consists of conceptual analysis, defining the observational space, and constructing summary statistics that can help us to identify issues in the model specification.</p>
<p><em>Conceptual Analysis</em></p>
<p>In section <a href="motivating-data.html#toj-task">2.2</a> I discussed the experimental setup and data collection. To reiterate, subjects are presented with two stimuli separated by some temporal delay, and they are asked to respond as to their perception of the temporal order. There are 45 subjects with 15 each in the young, middle, and older age groups. As the SOA becomes larger in the positive direction, subjects are expected to give more “positive” responses, and as the SOA becomes larger in the negative direction, more “negative” responses are expected. By the way the experiment and responses are constructed, there is no expectation to see a reversal of this trend unless there was an issue with the subject’s understanding of the directions given to them or an error in the recording device.</p>
<p>After the first experimental block the subjects go through a recalibration period, and repeat the experiment again. The interest is in seeing if the recalibration has an effect on temporal sensitivity and perceptual synchrony, and if the effect is different for each age group.</p>
<p><em>Define Observational Space</em></p>
<p>The response that subjects give during a TOJ task is recorded as a zero or a one (see section <a href="motivating-data.html#toj-task">2.2</a>), and their relative performance is determined by the SOA value. Let <span class="math inline">\(y\)</span> represent the binary outcome of a trial and let <span class="math inline">\(x\)</span> be the SOA value.</p>
<p><span class="math display">\[\begin{align*}
y_i &amp;\in \lbrace 0, 1\rbrace \\
x_i &amp;\in \mathbb{R}
\end{align*}\]</span></p>
<p>If the SOA values are fixed like in the audiovisual task, then the responses can be aggregated into binomial counts, <span class="math inline">\(k\)</span>.</p>
<p><span class="math display">\[
k_i, n_i \in \mathbb{Z}_0^+, k_i \le n_i
\]</span></p>
<p>In the above expression, <span class="math inline">\(\mathbb{Z}_0^+\)</span> represents the set of non-negative integers. Notice that the number of trials <span class="math inline">\(n\)</span> has an index variable <span class="math inline">\(i\)</span>. This is because the number of trials per SOA is not fixed between blocks. In the pre-adaptation block, there are five trials per SOA compared to three in the post-adaptation block. So if observation 32 is recorded during a “pre” block, <span class="math inline">\(n_{32} = 5\)</span>, and if observation 1156 is during a “post” block, <span class="math inline">\(n_{1156} = 3\)</span>. Of course this is assuming that each subject completed all trials in the block, but the flexibility of the indexing can manage even if they didn’t.</p>
<p>Then there are also three categorical variables – age group, subject ID, and trial (block). The first two are treated as factor variables<a href="#fn8" class="footnote-ref" id="fnref8"><sup>8</sup></a>. Rather than using one-hot encoding or dummy variables, the age levels are left as categories and a coefficient is fit for each level. Among the benefits of this approach is the ease of interpretation and ease of working with the data programmatically. This is especially true at the subject level. If a dummy variables was used for all 45 subjects, we would have 44 different dummy variables to work with times the number of coefficients that make estimates at the subject level. The number of parameters in the model grows rapidly as the model complexity grows.</p>
<p>Age groups and individual subjects can be indexed in the same way that number of trials is indexed. <span class="math inline">\(S_i\)</span> refers to the subject in record <span class="math inline">\(i\)</span>, and similarly <span class="math inline">\(G_i\)</span> refers to the age group of that subject. Observation 63 is for record ID av-post1-M-f-HG, so then <span class="math inline">\(S_{63}\)</span> is M-f-HG and <span class="math inline">\(G_{63}\)</span> is middle_age. Under the hood of R, these factor levels are represented as integers (e.g. middle age group level is stored internally as the number 2).</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="workflow.html#cb1-1"></a>(x &lt;-<span class="st"> </span><span class="kw">factor</span>(<span class="kw">c</span>(<span class="st">&quot;a&quot;</span>, <span class="st">&quot;a&quot;</span>, <span class="st">&quot;b&quot;</span>, <span class="st">&quot;c&quot;</span>)))</span>
<span id="cb1-2"><a href="workflow.html#cb1-2"></a><span class="co">#&gt; [1] a a b c</span></span>
<span id="cb1-3"><a href="workflow.html#cb1-3"></a><span class="co">#&gt; Levels: a b c</span></span>
<span id="cb1-4"><a href="workflow.html#cb1-4"></a><span class="kw">storage.mode</span>(x)</span>
<span id="cb1-5"><a href="workflow.html#cb1-5"></a><span class="co">#&gt; [1] &quot;integer&quot;</span></span></code></pre></div>
<p>This data storage representation can later be exploited for the Stan model.</p>
<p>The pre- and post-adaptation categories are treated as a binary indicator referred to as <span class="math inline">\(trt\)</span> (short for treatment) since there are only two levels in the category. In this setup, a value of 1 indicates a post-adaptation block. I chose this encoding over the reverse because the pre-adaptation block is like the baseline performance, and it seemed more appropriate to interpret the post-adaptation block as turning on some effect. Using a binary indicator in a regression setting may not be the best practice as I discuss in section <a href="workflow.html#iter2">3.2</a>.</p>
<p>In the Stan modeling language, data for a binomial model with subject and age group levels and treatment is specified as</p>

<pre><code>data {
  int N;        // Number of observations
  int N_S;      // Number of subject levels
  int N_G;      // Number of age group levels
  int N_T;      // Number of treatment/control groups
  int n[N];     // Trials per SOA
  int k[N];     // binomial counts
  vector[N] x;  // SOA values
  int S[N];     // Subject identifier
  int G[N];     // Age group identifier
  int trt[N];   // Treatment indicator
}</code></pre>

<p>In Stan (and unlike in R), data types must be statically declared. While sometimes a nuisance, this requirement aids in something called <em>type inference</em>, and also lets Stan optimize certain parts of the model.</p>
<p><em>Construct Summary Statistics</em></p>
<p>In order to effectively challenge the validity of the model, a set of summary statistics are constructed that help answer the questions of domain expertise consistency and model adequacy. We are studying the affects of age and temporal recalibration through the PSS and JND (see section <a href="motivating-data.html#psycho-experiments">2.1</a>), so it is natural to define summary statistics around these quantities to verify model consistency. Additionally the PSS and JND can be computed regardless of the model parameterization or chosen psychometric function.</p>
<p>By the experimental setup and recording process, it is impossible that a properly conducted block would result in a JND less than 0 (i.e. the psychometric function is always non-decreasing), so that can be a lower limit for its threshold. On the other end it is unlikely that it will be beyond the limits of the SOA values, but even more concrete, it seems unlikely (though not impossible) that the just noticeable difference would be more than a second.</p>
<p>The lower bound on the JND can be further refined if we draw information from other sources. Some studies show that we cannot perceive time differences below 30 ms, and others show that an input lag as small as 100ms can impair a person’s typing ability. Then according to these studies, a time delay of 100ms is enough to notice, and so a just noticeable difference should be much less than one second – much closer to 100ms. I’ll continue to use one second as an extreme estimate indicator, but will incorporate this knowledge when it comes to selecting priors.</p>
<p>As for the point of subjective simultaneity, it can be either positive or negative, with the belief that larger values are more rare. Some studies suggest that for audio-visual TOJ tasks, the separation between stimuli need to be as little as 20 milliseconds for subjects to be able to determine which modality came first <span class="citation">(Vatakis et al. <a href="#ref-vatakis2007influence" role="doc-biblioref">2007</a>)</span>. Other studies suggest that our brains can detect temporal differences as small as 30 milliseconds. If these values are to be believed then we should be skeptical of PSS estimates larger than say 150 milliseconds in absolute value, just to be safe.</p>
<p>A histogram of computed PSS and JND values will suffice for summary statistics. We can estimate the proportion of values that fall outside of our limits defined above, and use them as indications of problems with the model fitting or conceptual understanding.</p>
<p><strong>Post-Model, Pre-Data</strong></p>
<p>It is now time to define priors for the model, while still not having looked at the [distribution of] data. The priors should be motivated by domain expertise and <em>prior knowledge</em>, not the data. There are also many choices when it comes to selecting a psychometric (sigmoid) function. Common ones are logistic, Gaussian, and Weibull.</p>
<div class="figure" style="text-align: center"><span id="fig:ch031-pf-assortment"></span>
<img src="030-workflow_files/figure-html/ch031-pf-assortment-1.png" alt="Assortment of psychometric functions." width="70%" />
<p class="caption">
Figure 3.1: Assortment of psychometric functions.
</p>
</div>
<p>The Weibull psychometric function is more common when it comes to 2-AFC psychometric experiments where the independent variable is a stimulus intensity (non-negative) and the goal is signal detection. The data in this paper includes both positive and negative SOA values, so the Weibull is not a natural choice. In fact, because this is essentially a model for logistic regression, my first choice is the logistic function as it is the canonical choice for Binomial data. Additionally, the data in this study are reversible. The label of a positive response can be swapped with the label of a negative response and the inferences should remain the same. Since there is no natural ordering, it makes more sense for the psychometric function to be symmetric, e.g. the logistic and Gaussian. I use symmetric loosely to mean that probability density function (PDF) is symmetric about its middle. More specifically, the distribution has zero skewness.</p>
<p>In practice, there is little difference in inference between the <em>logit</em> and <em>probit</em> links, but computationally the logit link is more efficient. I am also more familiar with working on the log-odds scale compared to the probit scale, so I make the decision to go forward with the logistic function. In <a href="model-checking.html#model-checking">chapter 4</a> I will show how even with a mis-specified link function, we can still achieve accurate predictions.</p>
<p><em>Develop Model</em></p>
<p>Before moving on to specifying priors, I think it is appropriate to provide a little more background into generalized linear models (GLMs) and their role in working with psychometric functions. A GLM allows the linear model to be related to the outcome variable via a <em>link</em> function. An example of this is the logit link - the inverse of the logistic function. The logistic function, <span class="math inline">\(F\)</span>, takes <span class="math inline">\(x \in \mathbb{R}\)</span> and constrains the output to be in <span class="math inline">\((0, 1)\)</span>.</p>
<p><span class="math display" id="eq:logistic">\[\begin{equation}
  F(\theta) = \frac{1}{1 + \exp\left(-\theta\right)}
  \tag{3.2}
\end{equation}\]</span></p>
<p>Since <span class="math inline">\(F\)</span> is a strictly increasing and continuous function, it has an inverse, and the link for <a href="workflow.html#eq:logistic">(3.2)</a> is the log-odds or logit function.</p>
<p><span class="math display" id="eq:logit">\[\begin{equation}
  F^{-1}(\pi) = \mathrm{logit}(\pi) = \ln\left(\frac{\pi}{1 - \pi}\right)
  \tag{3.3}
\end{equation}\]</span></p>
<p>By taking <span class="math inline">\((F^{-1} \circ F)(\theta)\)</span> we can arrive at a relationship that is linear in <span class="math inline">\(\theta\)</span>.</p>
<p><span class="math display">\[\begin{align*}
  \pi = F(\theta) \Longleftrightarrow F^{-1}(\pi) &amp;= F^{-1}(F(\theta)) \\
  &amp; = \ln\left(\frac{F(\theta)}{1 - F(\theta)}\right) \\
  &amp;= \ln(F(\theta)) - \ln(1 - F(\theta)) \\
  &amp;= \ln\left(\frac{1}{1 + \exp(-\theta)}\right) - \ln\left(\frac{\exp(-\theta)}{1 + \exp(-\theta)}\right) \\
  &amp;= - \ln(1 + \exp(-\theta)) - \ln(\exp(-\theta)) + \ln(1 + \exp(-\theta)) \\
  &amp;= - \ln(\exp(-\theta)) \\
  &amp;= \theta
\end{align*}\]</span></p>
<p>The purpose of all this setup is to show that a model for the psychometric function can be specified using a linear predictor, <span class="math inline">\(\theta\)</span>. Given a simple slope-intercept model, one would typically write the linear predictor as</p>
<p><span class="math display" id="eq:linearform1">\[\begin{equation}
  \theta = \alpha + \beta x
  \tag{3.4}
\end{equation}\]</span></p>
<p>This isn’t the only acceptable form; it could be written in the centered parameterization</p>
<p><span class="math display" id="eq:linearform2">\[\begin{equation}
  \theta = \beta(x - a)
  \tag{3.5}
\end{equation}\]</span></p>
<p>Both parameterizations will describe the same geometry, so why should it matter which form is chosen? Clearly the interpretation of the parameters change between the two models, but the reason becomes clear when you consider how the linear model relates back to the physical properties that the psychometric model describes. Take equation <a href="workflow.html#eq:linearform1">(3.4)</a>, substitute it in to <a href="workflow.html#eq:logistic">(3.2)</a>, and then take the logit of both sides</p>
<p><span class="math display" id="eq:pfform1">\[\begin{equation}
  \mathrm{logit}(\pi) = \alpha+\beta x
  \tag{3.6}
\end{equation}\]</span></p>
<p>Now recall that the PSS is defined as the SOA values such that the response probability, <span class="math inline">\(\pi\)</span>, is <span class="math inline">\(0.5\)</span>. Substituting <span class="math inline">\(\pi = 0.5\)</span> into <a href="workflow.html#eq:pfform1">(3.6)</a> and solving for <span class="math inline">\(x\)</span> yields</p>
<p><span class="math display">\[
pss = -\frac{\alpha}{\beta}
\]</span></p>
<p>Similarly, the JND is defined as the difference between the SOA value at the 84% level and the PSS. Substituting <span class="math inline">\(\pi = 0.84\)</span> into <a href="workflow.html#eq:pfform1">(3.6)</a>, solving for <span class="math inline">\(x\)</span>, and subtracting off the pss yields</p>
<p><span class="math display" id="eq:jnd1">\[\begin{equation}
  jnd = \frac{\mathrm{logit}(0.84)}{\beta}
  \tag{3.7}
\end{equation}\]</span></p>
<p>From the conceptual analysis, it is easy to define priors for the PSS and JND, but then how does one set the priors for <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span>? Let’s say the prior for the just noticeable difference is <span class="math inline">\(jnd \sim \pi_j\)</span>. Then the prior for <span class="math inline">\(\beta\)</span> would be</p>
<p><span class="math display">\[
\beta \sim \frac{\mathrm{logit}(0.84)}{\pi_j}
\]</span></p>
<p>The log-normal distribution has a nice property where its multiplicative inverse is still a log-normal distribution. We could let <span class="math inline">\(\pi_j = \mathrm{Lognormal}(\mu, \sigma^2)\)</span> and then <span class="math inline">\(\beta\)</span> would be distributed as</p>
<p><span class="math display">\[
\beta \sim \mathrm{Lognormal}(-\mu + \ln(\mathrm{logit}(0.84)), \sigma^2)
\]</span></p>
<p>This is acceptable, as it was determined last chapter that the slope must always be positive, and a log-normal distribution constrains the support to postive real numbers. Next suppose that the prior distribution for the PSS is <span class="math inline">\(pss \sim \pi_p\)</span>. Then the prior for <span class="math inline">\(\alpha\)</span> is</p>
<p><span class="math display">\[
\alpha \sim -\pi_p \cdot \beta
\]</span></p>
<p>If <span class="math inline">\(\pi_p\)</span> is set to a log-normal distribution as well, then <span class="math inline">\(\pi_p \cdot \beta\)</span> would also be log-normal, but there is still the problem of the negative sign. If <span class="math inline">\(\alpha\)</span> is always negative, then the PSS will also always be negative, which is certainly not always true. Furthermore, I don’t want to <em>a priori</em> put more weight on positive PSS values compared to negative ones, for which a lognormal distribution would not do.</p>
<p>Let’s now go back and consider using equation <a href="workflow.html#eq:linearform2">(3.5)</a> and repeat the above process.</p>
<p><span class="math display" id="eq:pfform2">\[\begin{equation}
  \mathrm{logit}(\pi) = \beta(x - a)
  \tag{3.8}
\end{equation}\]</span></p>
<p>The just noticeable difference is still given by <a href="workflow.html#eq:jnd1">(3.7)</a> and so the same method for choosing a prior can be used, but the PSS is now given by</p>
<p><span class="math display">\[
pss = \alpha
\]</span></p>
<p>This is a fortunate consequence of using <a href="workflow.html#eq:linearform2">(3.5)</a> because now the JND only depends on <span class="math inline">\(\beta\)</span> and the PSS only depends on <span class="math inline">\(\alpha\)</span>, and now <span class="math inline">\(\alpha\)</span> can literally be interpreted as the PSS of the estimated psychometric function! Also thrown in is the ability to set a prior for <span class="math inline">\(\alpha\)</span> that is symmetric around <span class="math inline">\(0\)</span> like a Gaussian distribution.</p>
<p>This also brings me to point out the first benefit of using a modeling language like Stan over others. For fitting GLMs in R, there are a handful of functions that utilize MLE like <code>stats::glm</code> and others that use Bayesian methods like <code>rstanarm::stan_glm</code> and <code>arm::bayesglm</code> <span class="citation">(Gabry and Goodrich <a href="#ref-R-rstanarm" role="doc-biblioref">2020</a>; Gelman and Su <a href="#ref-R-arm" role="doc-biblioref">2020</a>)</span>. Each of these functions requires the linear predictor to be in the form of <a href="workflow.html#eq:linearform1">(3.4)</a>. The <code>stan_glm</code> function actually uses Stan in the backend to fit a model, but is limited to priors from the Student t family of distributions. By writing the model directly in Stan, the linear model can be parameterized in any way and with any prior distribution, and so allows for much more expressive modeling - a key aspect of this principled workflow.</p>
<p>For the first iteration of this model, I am going to start with the simplest model that captures the structure of the data without including information about age group, treatment, or subject. Here is a simple model that draws information from the conceptual analysis.</p>
<p><span class="math display">\[\begin{align*}
  k_i &amp;\sim \mathrm{Binomial}(n_i, p_i) \\
  \mathrm{logit}(p_i) &amp;= \beta ( x_i - \alpha )
\end{align*}\]</span></p>
<p>Since I am using the linear model from <a href="workflow.html#eq:linearform2">(3.5)</a>, setting the priors for <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span> is relatively straightforward. The PSS can be positive or negative without any expected bias towards either, so a symmetric distribution like the Gaussian is a fine choice for <span class="math inline">\(\alpha\)</span> without having any other knowledge about the distribution of PSS values. Since I said earlier that a PSS value more than 150ms in absolute value is unlikely, I can define a Gaussian prior such that <span class="math inline">\(P(|pss| &gt; 0.150) \approx 0.01\)</span>. Since the prior does not need to be exact, the following mean and variance suffice</p>
<p><span class="math display">\[
pss \sim \mathcal{N}(0, 0.06^2) \Longleftrightarrow \alpha \sim \mathcal{N}(0, 0.06^2)
\]</span></p>
<p>For the just noticeable difference, I will continue to use the log-normal distribution because it is constrained to positive values and has the nice reciprocal property. The JND is expected to be close to 100ms and extremely unlikely to exceed 1 second. This implies a prior such that the mean is around 100ms and the bulk of the distribution is below 1 second - i.e. <span class="math inline">\(E[X] \approx 0.100\)</span> and <span class="math inline">\(P(X &lt; 1) \approx 0.99\)</span>. This requires solving a system of nonlinear equations in two variables</p>
<p><span class="math display">\[
\begin{cases}
E[X] = 0.100 = \exp\left(\mu + \sigma^2 / 2\right) \\
P(X &lt; 1) = 0.99 = 0.5 + 0.5 \cdot \mathrm{erf}\left[\frac{\ln (1) - \mu}{\sqrt{2} \cdot \sigma}\right]
\end{cases}
\]</span></p>
<p>This nonlinear system can be solved using Stan’s algebraic solver.</p>
<pre class="stan"><code>functions {
  vector system(vector y, vector theta, real[] x_r, int[] x_i) {
    vector[2] z;
    z[1] = exp(y[1] + y[2]^2 / 2) - theta[1];
    z[2] = 0.5 + 0.5 * erf(-y[1] / (sqrt(2) * y[2])) - theta[2];
    return z;
  }
}
transformed data {
  vector[2] y_guess = [1, 1]&#39;;
  real x_r[0];
  int x_i[0];
}
transformed parameters {
  vector[2] theta = [0.100, 0.99]&#39;;
  vector[2] y;
  y = algebra_solver(system, y_guess, theta, x_r, x_i);
}</code></pre>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb4-1"><a href="workflow.html#cb4-1"></a>fit &lt;-<span class="st"> </span><span class="kw">sampling</span>(prior_jnd, <span class="dt">iter=</span><span class="dv">1</span>, <span class="dt">warmup=</span><span class="dv">0</span>, <span class="dt">chains=</span><span class="dv">1</span>, <span class="dt">refresh=</span><span class="dv">0</span>,</span>
<span id="cb4-2"><a href="workflow.html#cb4-2"></a>                <span class="dt">seed=</span><span class="dv">31</span>, <span class="dt">algorithm=</span><span class="st">&quot;Fixed_param&quot;</span>)</span>
<span id="cb4-3"><a href="workflow.html#cb4-3"></a>sol &lt;-<span class="st"> </span><span class="kw">extract</span>(fit)</span>
<span id="cb4-4"><a href="workflow.html#cb4-4"></a>sol<span class="op">$</span>y</span>
<span id="cb4-5"><a href="workflow.html#cb4-5"></a><span class="co">#&gt;           </span></span>
<span id="cb4-6"><a href="workflow.html#cb4-6"></a><span class="co">#&gt; iterations   [,1]  [,2]</span></span>
<span id="cb4-7"><a href="workflow.html#cb4-7"></a><span class="co">#&gt;       [1,] -7.501 3.225</span></span></code></pre></div>
<p>The solver has determined that <span class="math inline">\(\mathrm{Lognormal}(-7.5, 3.2^2)\)</span> is the appropriate prior. However, simulating some values from this distribution produces a lot of extremely small values (<span class="math inline">\(&lt;10^{-5}\)</span>) and a few extremely large values (<span class="math inline">\(\approx 10^2\)</span>). This is because the expected value of a log-normal random variable depends on both the mean and standard deviation. If the median is used in place for the mean, then a more acceptable prior may be determined.</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="workflow.html#cb5-1"></a>fit &lt;-<span class="st"> </span><span class="kw">sampling</span>(prior_jnd_using_median, <span class="dt">iter=</span><span class="dv">1</span>, <span class="dt">warmup=</span><span class="dv">0</span>, <span class="dt">chains=</span><span class="dv">1</span>, <span class="dt">refresh=</span><span class="dv">0</span>,</span>
<span id="cb5-2"><a href="workflow.html#cb5-2"></a>                <span class="dt">seed=</span><span class="dv">31</span>, <span class="dt">algorithm=</span><span class="st">&quot;Fixed_param&quot;</span>)</span>
<span id="cb5-3"><a href="workflow.html#cb5-3"></a>sol &lt;-<span class="st"> </span><span class="kw">extract</span>(fit)</span>
<span id="cb5-4"><a href="workflow.html#cb5-4"></a>sol<span class="op">$</span>y</span>
<span id="cb5-5"><a href="workflow.html#cb5-5"></a><span class="co">#&gt;           </span></span>
<span id="cb5-6"><a href="workflow.html#cb5-6"></a><span class="co">#&gt; iterations   [,1]   [,2]</span></span>
<span id="cb5-7"><a href="workflow.html#cb5-7"></a><span class="co">#&gt;       [1,] -2.303 0.9898</span></span></code></pre></div>
<p>Sampling from a log-normal distribution with these parameters and plotting the histogram shows no inconsistency with the domain expertise.</p>
<p><img src="030-workflow_files/figure-html/ch031-Risky-Lion-1.png" width="70%" style="display: block; margin: auto;" /></p>
<p>So now with a prior for the JND, the prior for <span class="math inline">\(\beta\)</span> can be determined.</p>
<p><span class="math display">\[
jnd \sim \mathrm{Lognormal}(-2.3, 0.99^2) \Longleftrightarrow \frac{1}{jnd} \sim \mathrm{Lognormal}(2.3, 0.99^2)
\]</span></p>
<p>and</p>
<p><span class="math display">\[
\beta = \frac{\mathrm{logit}(0.84)}{jnd} \sim \mathrm{Lognormal}(2.8, 0.99^2)
\]</span></p>
<p>The priors do not need to be too exact. Rounding the parameters for <span class="math inline">\(\beta\)</span>, the simple model is</p>
<p><span class="math display">\[\begin{align*}
  k_i &amp;\sim \mathrm{Binomial}(n_i, p_i) \\
  \mathrm{logit}(p_i) &amp;= \beta ( x_i - \alpha ) \\
  \alpha &amp;\sim \mathcal{N}(0, 0.06^2) \\
  \beta &amp;\sim \mathrm{Lognormal}(3, 1^2)
\end{align*}\]</span></p>
<p>and in Stan, the model code is</p>

<pre class="stan"><code>data {
  int N;
  int n[N];
  int k[N];
  vector[N] x;
}
parameters {
  real alpha;
  real&lt;lower=0&gt; beta;
}
model {
  vector[N] p = beta * (x - alpha);
  alpha ~ normal(0, 0.05);
  beta ~ lognormal(3.0, 1.5);
  k ~ binomial_logit(n, p);
}</code></pre>

<p>Notice that the model block is nearly identical to the mathematical model!</p>
<p><em>Construct Summary Functions</em></p>
<p>Whew! that was a lot of work to define the priors for just two parameters. Thankfully going forward not as much work will need to be done to expand the model. The next step is to construct any relevant summary functions. Since the distribution of posterior PSS and JND values are needed for the summary statistics, it will be nice to have a function that can take in the posterior samples for <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span> and return the PSS and JND values. I’ll define <span class="math inline">\(Q\)</span> as a more general function that takes in the two parameters and a probability, <span class="math inline">\(\pi\)</span>, and returns the distribution of SOA values at <span class="math inline">\(\pi\)</span>.</p>
<p><span class="math display" id="eq:summfun1">\[\begin{equation}
  Q(\pi; \alpha, \beta) = \frac{\mathrm{logit(\pi)}}{\beta} + \alpha
  \tag{3.9}
\end{equation}\]</span></p>
<p>The function can be defined in R as</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb7-1"><a href="workflow.html#cb7-1"></a>Q &lt;-<span class="st"> </span><span class="cf">function</span>(p, a, b) <span class="kw">qlogis</span>(p) <span class="op">/</span><span class="st"> </span>b <span class="op">+</span><span class="st"> </span>a</span></code></pre></div>
<p>With <span class="math inline">\(Q\)</span>, the PSS and JND can be calculated as</p>
<p><span class="math display">\[\begin{align}
  pss &amp;= Q(0.5) \\
  jnd &amp;= Q(0.84) - Q(0.5)
\end{align}\]</span></p>
<p><em>Simulate Bayesian Ensemble</em></p>
<p>During this step, I simulate the Bayesian ensemble and later feed the prior values into the summary functions in order to verify that there are no other inconsistencies with domain knowledge. Since the model is fairly simple, I will simulate directly in R.</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb8-1"><a href="workflow.html#cb8-1"></a><span class="kw">set.seed</span>(<span class="dv">124</span>)</span>
<span id="cb8-2"><a href="workflow.html#cb8-2"></a>n &lt;-<span class="st"> </span><span class="dv">10000</span></span>
<span id="cb8-3"><a href="workflow.html#cb8-3"></a></span>
<span id="cb8-4"><a href="workflow.html#cb8-4"></a>a &lt;-<span class="st"> </span><span class="kw">rnorm</span>(n, <span class="dv">0</span>, <span class="fl">0.06</span>)</span>
<span id="cb8-5"><a href="workflow.html#cb8-5"></a>b &lt;-<span class="st"> </span><span class="kw">rlnorm</span>(n, <span class="fl">3.0</span>, <span class="dv">1</span>)</span>
<span id="cb8-6"><a href="workflow.html#cb8-6"></a></span>
<span id="cb8-7"><a href="workflow.html#cb8-7"></a>dat &lt;-<span class="st"> </span><span class="kw">with</span>(av_dat, <span class="kw">list</span>(<span class="dt">N =</span> N, <span class="dt">x =</span> x, <span class="dt">n =</span> n)) </span>
<span id="cb8-8"><a href="workflow.html#cb8-8"></a>n_obs &lt;-<span class="st"> </span><span class="kw">length</span>(dat<span class="op">$</span>x)</span>
<span id="cb8-9"><a href="workflow.html#cb8-9"></a></span>
<span id="cb8-10"><a href="workflow.html#cb8-10"></a>idx &lt;-<span class="st"> </span><span class="kw">sample</span>(<span class="dv">1</span><span class="op">:</span>n, n_obs, <span class="dt">replace =</span> <span class="ot">TRUE</span>)</span>
<span id="cb8-11"><a href="workflow.html#cb8-11"></a>probs &lt;-<span class="st"> </span><span class="kw">logistic</span>(b[idx] <span class="op">*</span><span class="st"> </span>(dat<span class="op">$</span>x <span class="op">-</span><span class="st"> </span>a[idx]))</span>
<span id="cb8-12"><a href="workflow.html#cb8-12"></a>sim_k &lt;-<span class="st"> </span><span class="kw">rbinom</span>(n_obs, dat<span class="op">$</span>n, probs)</span></code></pre></div>
<p><em>Prior Checks</em></p>
<p>This step pertains to ensuring that prior estimates are consistent with domain expertise. I already did that in the model construction step by sampling values for the just noticeable difference. The first prior chosen was not producing JND estimates that were consistent with domain knowledge, so I adjusted accordingly. That check would normally be done during this step, and I would have had to return to the model development step.</p>
<p>Figure <a href="workflow.html#fig:ch030-prior-pf-plot">3.2</a> shows the distribution of prior psychometric functions derived from the simulated ensemble. There are a few very steep and very shallow curves, but the majority fall within a range that appears likely.</p>
<div class="figure" style="text-align: center"><span id="fig:ch030-prior-pf-plot"></span>
<img src="030-workflow_files/figure-html/ch030-prior-pf-plot-1.png" alt="Prior distribution of psychometric functions using the priors for alpha and beta." width="70%" />
<p class="caption">
Figure 3.2: Prior distribution of psychometric functions using the priors for alpha and beta.
</p>
</div>
<p>Additionally most of the PSS values are within <span class="math inline">\(\pm 0.1\)</span> with room to allow for some larger values. Let’s check the prior distribution of PSS and JND values.</p>
<div class="figure" style="text-align: center"><span id="fig:ch031-prior-pss-plot"></span>
<img src="030-workflow_files/figure-html/ch031-prior-pss-plot-1.png" alt="PSS prior distribution." width="70%" />
<p class="caption">
Figure 3.3: PSS prior distribution.
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:ch031-prior-jnd-plot"></span>
<img src="030-workflow_files/figure-html/ch031-prior-jnd-plot-1.png" alt="JND prior distribution." width="70%" />
<p class="caption">
Figure 3.4: JND prior distribution.
</p>
</div>
<p>I am satisfied with the prior coverage of the PSS and JND values, and there are only a few samples that go beyond the extremes that were specified in the summary statistics step.</p>
<p><em>Configure Algorithm</em></p>
<p>There are a few parameters that can be set for Stan. On the user side, the main parameters are the number of iterations, the number of warm-up iterations, the target acceptance rate, and the number of chains to run. The NUTS algorithm samples in two phases: a warm-up phase and a sampling phase. During the warm-up phase, the sampler is automatically tuning three internal parameters that can significantly affect the sampling efficiency. By default, the Stan function will use half the number of iterations for warm-up and the other half for actual sampling. The full details of Stan’s HMC algorithm is described in the Stan reference manual. For now I am going to use the default algorithm parameters in Stan, and will tweak them later if and when issues arise.</p>
<p><em>Fit Simulated Ensemble</em></p>
<p>Nothing to say here. Only code.</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb9-1"><a href="workflow.html#cb9-1"></a>sim_dat &lt;-<span class="st"> </span><span class="kw">with</span>(av_dat, <span class="kw">list</span>(<span class="dt">N =</span> N, <span class="dt">x =</span> x, <span class="dt">n =</span> n, <span class="dt">k =</span> sim_k)) </span>
<span id="cb9-2"><a href="workflow.html#cb9-2"></a>m031 &lt;-<span class="st"> </span><span class="kw">sampling</span>(m031_stan, <span class="dt">data =</span> sim_dat, </span>
<span id="cb9-3"><a href="workflow.html#cb9-3"></a>                 <span class="dt">chains =</span> <span class="dv">4</span>, <span class="dt">cores =</span> <span class="dv">4</span>, <span class="dt">refresh =</span> <span class="dv">0</span>)</span></code></pre></div>
<p><em>Algorithmic Calibration</em></p>
<p>One benefit of using HMC over other samplers like Gibbs sampling is that HMC offers diagnostic tools for the health of chains and the ability to check for <em>divergent transitions</em>. Recall that the HMC and NUTS algorithm can be imagined as a physics simulation of a particle in a potential energy field, and a random momentum is imparted on the particle. The sum of the potential energy and the kinetic energy of the system is called the Hamiltonian, and is conserved along the trajectory of the particle (<span class="citation">(<span class="citeproc-not-found" data-reference-id="stanref"><strong>???</strong></span>)</span>). The path that the particle takes is a discrete approximation to the actual path where the position of the particle is updated in small steps called <em>leapfrog steps</em> (see <span class="citation">Leimkuhler and Reich (<a href="#ref-leimkuhler2004simulating" role="doc-biblioref">2004</a>)</span> for a detailed explanation of the leapfrog algorithm). A divergent transition happens when the simulated trajectory is far from the true trajectory as measured by the Hamiltonian.</p>
<p>To check the basic diagnostics of the model, I run the following code.</p>

<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb10-1"><a href="workflow.html#cb10-1"></a><span class="kw">check_hmc_diagnostics</span>(m031)</span>
<span id="cb10-2"><a href="workflow.html#cb10-2"></a><span class="co">#&gt; </span></span>
<span id="cb10-3"><a href="workflow.html#cb10-3"></a><span class="co">#&gt; Divergences:</span></span>
<span id="cb10-4"><a href="workflow.html#cb10-4"></a><span class="co">#&gt; 0 of 4000 iterations ended with a divergence.</span></span>
<span id="cb10-5"><a href="workflow.html#cb10-5"></a><span class="co">#&gt; </span></span>
<span id="cb10-6"><a href="workflow.html#cb10-6"></a><span class="co">#&gt; Tree depth:</span></span>
<span id="cb10-7"><a href="workflow.html#cb10-7"></a><span class="co">#&gt; 0 of 4000 iterations saturated the maximum tree depth of 10.</span></span>
<span id="cb10-8"><a href="workflow.html#cb10-8"></a><span class="co">#&gt; </span></span>
<span id="cb10-9"><a href="workflow.html#cb10-9"></a><span class="co">#&gt; Energy:</span></span>
<span id="cb10-10"><a href="workflow.html#cb10-10"></a><span class="co">#&gt; E-BFMI indicated no pathological behavior.</span></span></code></pre></div>

<p>There is no undesirable behavior from this model, so next I check the summary statistics of the estimated parameters. The <span class="math inline">\(\hat{R}\)</span> statistic is a comparison of the measure of variance within chains and between chains. When chains have converged to a stationary distribution, the variance within and between chains is the same, and the ratio is one. Values of <span class="math inline">\(\hat{R} &gt; 1.1\)</span> are usually indicative of chains that have not converged to a common distribution. Lastly there is the effective sample size (<span class="math inline">\(N_{\mathrm{eff}}\)</span>) which is a loose measure for the autocorrelation within the parameter samples. As autocorrelation generally decreases as the lag increases, one can achieve a higher <span class="math inline">\(N_{\mathrm{eff}}\)</span> by running a chain with more samples and then <em>thinning</em> the samples, i.e. saving only every <span class="math inline">\(n^{th}\)</span> sample.</p>
<table class="table" style="margin-left: auto; margin-right: auto;">
<caption>
<span id="tab:ch031-Cloudy-Toupee">Table 3.2: </span>Summary statistics of the fitted Bayesian ensemble.
</caption>
<thead>
<tr>
<th style="text-align:left;">
parameter
</th>
<th style="text-align:right;">
mean
</th>
<th style="text-align:right;">
se_mean
</th>
<th style="text-align:right;">
sd
</th>
<th style="text-align:right;">
2.5%
</th>
<th style="text-align:right;">
97.5%
</th>
<th style="text-align:right;">
n_eff
</th>
<th style="text-align:right;">
Rhat
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
alpha
</td>
<td style="text-align:right;">
0.0061
</td>
<td style="text-align:right;">
0.0001
</td>
<td style="text-align:right;">
0.0035
</td>
<td style="text-align:right;">
-0.0007
</td>
<td style="text-align:right;">
0.0129
</td>
<td style="text-align:right;">
3728
</td>
<td style="text-align:right;">
1.000
</td>
</tr>
<tr>
<td style="text-align:left;">
beta
</td>
<td style="text-align:right;">
10.7726
</td>
<td style="text-align:right;">
0.0054
</td>
<td style="text-align:right;">
0.2473
</td>
<td style="text-align:right;">
10.3054
</td>
<td style="text-align:right;">
11.2600
</td>
<td style="text-align:right;">
2073
</td>
<td style="text-align:right;">
1.001
</td>
</tr>
</tbody>
</table>
<p>Both the <span class="math inline">\(\hat{R}\)</span> and <span class="math inline">\(N_{\mathrm{eff}}\)</span> look fine for both <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span>, thought it is slightly concerning that <span class="math inline">\(\alpha\)</span> is centered relatively far from zero. This could just be due to sampling variance, so I will continue on to the next step.</p>
<p><em>Inferential Calibration</em></p>
<p><strong>Post-Model, Post-Data</strong></p>
<p><em>Fit Observed Data</em></p>
<p>All of the work up until now has been done without peaking at the observed data. Satisfied with the model so far, I can now go ahead and run the data through.</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb11-1"><a href="workflow.html#cb11-1"></a>obs_dat &lt;-<span class="st"> </span><span class="kw">with</span>(av_dat, <span class="kw">list</span>(<span class="dt">N =</span> N, <span class="dt">x =</span> x, <span class="dt">n =</span> n, <span class="dt">k =</span> k)) </span>
<span id="cb11-2"><a href="workflow.html#cb11-2"></a>m031 &lt;-<span class="st"> </span><span class="kw">sampling</span>(m031_stan, <span class="dt">data =</span> obs_dat, </span>
<span id="cb11-3"><a href="workflow.html#cb11-3"></a>                 <span class="dt">chains =</span> <span class="dv">4</span>, <span class="dt">cores =</span> <span class="dv">4</span>, <span class="dt">refresh =</span> <span class="dv">0</span>)</span></code></pre></div>
<p><em>Diagnose Posterior Fit</em></p>
<p>Here I repeat the diagnostic checks that I used after fitting the simulated Bayesian ensemble.</p>

<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb12-1"><a href="workflow.html#cb12-1"></a><span class="kw">check_hmc_diagnostics</span>(m031)</span>
<span id="cb12-2"><a href="workflow.html#cb12-2"></a><span class="co">#&gt; </span></span>
<span id="cb12-3"><a href="workflow.html#cb12-3"></a><span class="co">#&gt; Divergences:</span></span>
<span id="cb12-4"><a href="workflow.html#cb12-4"></a><span class="co">#&gt; 0 of 4000 iterations ended with a divergence.</span></span>
<span id="cb12-5"><a href="workflow.html#cb12-5"></a><span class="co">#&gt; </span></span>
<span id="cb12-6"><a href="workflow.html#cb12-6"></a><span class="co">#&gt; Tree depth:</span></span>
<span id="cb12-7"><a href="workflow.html#cb12-7"></a><span class="co">#&gt; 0 of 4000 iterations saturated the maximum tree depth of 10.</span></span>
<span id="cb12-8"><a href="workflow.html#cb12-8"></a><span class="co">#&gt; </span></span>
<span id="cb12-9"><a href="workflow.html#cb12-9"></a><span class="co">#&gt; Energy:</span></span>
<span id="cb12-10"><a href="workflow.html#cb12-10"></a><span class="co">#&gt; E-BFMI indicated no pathological behavior.</span></span></code></pre></div>

<table class="table" style="margin-left: auto; margin-right: auto;">
<caption>
<span id="tab:ch031-Maroon-Oyster">Table 3.3: </span>Summary statistics of the fitted Bayesian ensemble.
</caption>
<thead>
<tr>
<th style="text-align:left;">
parameter
</th>
<th style="text-align:right;">
mean
</th>
<th style="text-align:right;">
se_mean
</th>
<th style="text-align:right;">
sd
</th>
<th style="text-align:right;">
2.5%
</th>
<th style="text-align:right;">
97.5%
</th>
<th style="text-align:right;">
n_eff
</th>
<th style="text-align:right;">
Rhat
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
alpha
</td>
<td style="text-align:right;">
0.0373
</td>
<td style="text-align:right;">
0.0001
</td>
<td style="text-align:right;">
0.0040
</td>
<td style="text-align:right;">
0.0293
</td>
<td style="text-align:right;">
0.0453
</td>
<td style="text-align:right;">
4035
</td>
<td style="text-align:right;">
0.9992
</td>
</tr>
<tr>
<td style="text-align:left;">
beta
</td>
<td style="text-align:right;">
8.4236
</td>
<td style="text-align:right;">
0.0039
</td>
<td style="text-align:right;">
0.1857
</td>
<td style="text-align:right;">
8.0771
</td>
<td style="text-align:right;">
8.7992
</td>
<td style="text-align:right;">
2311
</td>
<td style="text-align:right;">
1.0017
</td>
</tr>
</tbody>
</table>
<p>No indications of an ill-behaved posterior fit! Let’s also check the posterior distribution of <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span> against the prior density (<a href="workflow.html#fig:ch031-m031-posterior-alpha-beta">3.5</a>).</p>
<div class="figure" style="text-align: center"><span id="fig:ch031-m031-posterior-alpha-beta"></span>
<img src="030-workflow_files/figure-html/ch031-m031-posterior-alpha-beta-1.png" alt="Comparison of posterior distributions for alpha and beta to their respective prior distributions." width="70%" />
<p class="caption">
Figure 3.5: Comparison of posterior distributions for alpha and beta to their respective prior distributions.
</p>
</div>
<p>The posterior distributions for <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span> are well within the range determined by domain knowledge, and highly concentrated due to both the large amount of data and the fact that this is a completely pooled model - no stratification. As expected, the prior for the JND could have been tighter with more weight below half a second compared to the one second limit used, but this is not prior information, so it is not prudent to change the prior in this manner after having seen the posterior. As a rule of thumb, priors should only be updated as motivated by domain expertise and not by posterior distributions.</p>
<p><em>Posterior Retrodictive Checks</em></p>
<p>Finally it is time to run the posterior samples through the summary functions and then perform <em>retrodictive</em> checks. A retrodiction is using the posterior model to predict and compare to the observed data. This is simply done by drawing samples from the posterior and feeding in the observational data. This may be repeated to gain a retrodictive distribution.</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb13-1"><a href="workflow.html#cb13-1"></a>posterior_pss &lt;-<span class="st"> </span><span class="kw">Q</span>(<span class="fl">0.5</span>, p031<span class="op">$</span>alpha, p031<span class="op">$</span>beta)</span>
<span id="cb13-2"><a href="workflow.html#cb13-2"></a>posterior_jnd &lt;-<span class="st"> </span><span class="kw">Q</span>(<span class="fl">0.84</span>, p031<span class="op">$</span>alpha, p031<span class="op">$</span>beta) <span class="op">-</span><span class="st"> </span>posterior_pss</span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:ch031-posterior-pss-jnd-plot"></span>
<img src="030-workflow_files/figure-html/ch031-posterior-pss-jnd-plot-1.png" alt="Posterior distribution of the PSS and JND." width="70%" />
<p class="caption">
Figure 3.6: Posterior distribution of the PSS and JND.
</p>
</div>
<p>Neither of the posterior estimates for the PSS or JND exceed the extreme cutoffs set in the earlier steps, so I can be confident that the model is consistent with domain expertise. Let’s also take a second to appreciate how simple it is to visualize and summarize the distribution of values for these measures. Using classical techniques like MLE might require using bootstrap methods to estimate the distribution of parameter values, or one might approximate the parameter distributions using the mean and standard error of the mean to simulate new values. Since we have the entire posterior distribution we can calculate the distribution of transformed parameters by working directly with the posterior samples and be sure that the intervals are credible.</p>
<p>Next is to actually do the posterior retrodictions. I will do this in two steps to better show how the distribution of posterior psychometric functions relates to the observed data, and then compare the observed data to the retrodictions. Figure <a href="workflow.html#fig:ch031-posterior-pf-plot">3.7</a> shows the result of the first step.</p>
<div class="figure" style="text-align: center"><span id="fig:ch031-posterior-pf-plot"></span>
<img src="030-workflow_files/figure-html/ch031-posterior-pf-plot-1.png" alt="Posterior distribution of psychometric functions using pooled observations." width="70%" />
<p class="caption">
Figure 3.7: Posterior distribution of psychometric functions using pooled observations.
</p>
</div>
<p>Next I sample parameter values from the posterior distribution and use them to simulate a new data set. In the next iteration I will show how I can get Stan to automatically produce retrodictions for me in the model fitting step. The results of the posterior retrodictions are shown in figure <a href="workflow.html#fig:ch031-obs-vs-retro-plot">3.8</a>.</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb14-1"><a href="workflow.html#cb14-1"></a>alpha &lt;-<span class="st"> </span><span class="kw">sample</span>(p031<span class="op">$</span>alpha, n_obs, <span class="dt">replace =</span> <span class="ot">TRUE</span>)</span>
<span id="cb14-2"><a href="workflow.html#cb14-2"></a>beta  &lt;-<span class="st"> </span><span class="kw">sample</span>(p031<span class="op">$</span>beta, n_obs, <span class="dt">replace =</span> <span class="ot">TRUE</span>)</span>
<span id="cb14-3"><a href="workflow.html#cb14-3"></a>logodds &lt;-<span class="st"> </span>beta <span class="op">*</span><span class="st"> </span>(av_dat<span class="op">$</span>x <span class="op">-</span><span class="st"> </span>alpha)</span>
<span id="cb14-4"><a href="workflow.html#cb14-4"></a>probs &lt;-<span class="st"> </span><span class="kw">logistic</span>(logodds)</span>
<span id="cb14-5"><a href="workflow.html#cb14-5"></a>sim_k &lt;-<span class="st"> </span><span class="kw">rbinom</span>(n_obs, av_dat<span class="op">$</span>n, probs)</span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:ch031-obs-vs-retro-plot"></span>
<img src="030-workflow_files/figure-html/ch031-obs-vs-retro-plot-1.png" alt="Observed data compared to the posterior retrodictions. The data is post-stratified by block for easier visualization." width="70%" />
<p class="caption">
Figure 3.8: Observed data compared to the posterior retrodictions. The data is post-stratified by block for easier visualization.
</p>
</div>
<p>I want to make it clear exactly what the first iteration of this model tells us. It is the average distribution of underlying psychometric functions across all subjects and blocks. It cannot tell us what the differences are between pre- and post-adaptation blocks are, or even what the variation between subjects is. As such, it is only useful in determining if the average value for the PSS is different from 0 or if the average JND is different from some other predetermined level. This model is still useful given the right question, but this model cannot answer questions about group-level effects.</p>
<p>Figure <a href="workflow.html#fig:ch031-obs-vs-retro-plot">3.8</a> shows that the model captures the broad structure of the observed data, but is perhaps a bit under-dispersed in the tail ends of the SOA values. Besides this one issue, I am satisfied with the first iteration of this model and am ready to proceed to the next iteration.</p>
</div>
<div id="iter2" class="section level2">
<h2><span class="header-section-number">3.2</span> Iteration 2 (electric boogaloo)</h2>
<p>In this iteration I will be adding in the treatment and age groups into the model. There are no changes with the conceptual understanding of the experiment, and nothing to change with the observational space. As such I will be skipping the first three steps and go straight to the model development step. As I build the model, the number of changes from one iteration to the next should go to zero as the model <em>expands</em> to become only as complex as necessary to answer the research questions.</p>
<p><strong>Post-Model, Pre-Data</strong></p>
<p><em>Develop Model</em></p>
<p>To start, let’s add in the treatment indicator and put off consideration of adding in the age group levels. In classical statistics, it is added as an indicator variable (zero or one) for both the slope and intercept (varying slopes, varying intercepts model). Let <span class="math inline">\(trt\)</span> be <span class="math inline">\(0\)</span> if it is the pre-adaptation block and <span class="math inline">\(1\)</span> if the observation comes from the post-adaptation block.</p>
<p><span class="math display">\[
\theta = \alpha + \alpha_{trt} \times trt + \beta \times x + \beta_{trt}\times trt \times x
\]</span></p>
<p>Now when an observation comes from the pre-adaptation block (<span class="math inline">\(trt=0\)</span>) the linear predictor is given by</p>
<p><span class="math display">\[
\theta_{pre} = \alpha + \beta \times x
\]</span></p>
<p>and when an observation comes from the post-adaptation block (<span class="math inline">\(trt=1\)</span>) the linear predictor is</p>
<p><span class="math display">\[
\theta_{post} = (\alpha + \alpha_{trt}) + (\beta + \beta_{trt}) \times x
\]</span></p>
<p>This might seem like a natural way to introduce an indicator variable, but it comes with serious implications. This model implies that there is more uncertainty about the post-adaptation block compared to the baseline block, and this is not necessarily true.</p>
<p><span class="math display">\[\begin{align*}
\mathrm{Var}(\theta_{post}) &amp;= \mathrm{Var}((\alpha + \alpha_{trt}) + (\beta + \beta_{trt}) \times x) \\
&amp;= \mathrm{Var}(\alpha) + \mathrm{Var}(\alpha_{trt}) + x^2 \mathrm{Var}(\beta) + x^2\mathrm{Var}(\beta_{trt})
\end{align*}\]</span></p>
<p>On the other hand, the variance of <span class="math inline">\(\theta_{pre}\)</span> is</p>
<p><span class="math display">\[
\mathrm{Var}(\theta_{pre}) = \mathrm{Var}(\alpha) + x^2 \mathrm{Var}(\beta) \le \mathrm{Var}(\theta_{post})
\]</span></p>
<p>Furthermore, the intercept, <span class="math inline">\(\alpha\)</span>, is no longer the average response probability at <span class="math inline">\(x=0\)</span> for the entire data set, but is instead exclusively the average for the pre-adaptation block. This may not matter in certain analyses, but one nice property of multilevel models is the separation of population level estimates and group level estimates (fixed vs. mixed effects).</p>
<p>So instead the treatment variable is introduced into the linear model as a factor variable. This essentially means that each level in the treatment gets its own parameter estimate, and this also makes it easier to set priors when there are many levels in a group (such as for the subject level). The linear model, using equation <a href="workflow.html#eq:linearform2">(3.5)</a>, with the treatment is written as</p>
<p><span class="math display" id="eq:linearmodel2">\[\begin{equation}
  \theta = (\beta + \beta_{trt[i]}) \left[x_i - (\alpha + \alpha_{trt[i]})\right]
  \tag{3.10}
\end{equation}\]</span></p>
<p>As I add in more predictors and groups, equation <a href="workflow.html#eq:linearmodel2">(3.10)</a> will start to be more difficult to read. What I can do is break up the slope and intercept parameters and write the linear model as</p>
<p><span class="math display">\[\begin{align*}
\mu_\alpha &amp;= \alpha + \alpha_{trt[i]} \\
\mu_\beta &amp;= \beta + \beta_{trt[i]} \\
\theta &amp;= \mu_\beta (x - \mu_\alpha)
\end{align*}\]</span></p>
<p>In this way the combined parameters can be considered separately from the linear parameterization. Which leads me to consider the priors for <span class="math inline">\(\alpha_{trt}\)</span> and <span class="math inline">\(\beta_{trt}\)</span>. The way that we can turn an normal model with categorical predictors into a multilevel model is by allowing the priors to borrow information from other groups. This is accomplished by putting priors on priors. It is easier to write down the model first before explaining how it works.</p>
<p><span class="math display">\[\begin{align*}
k_i &amp;\sim \mathrm{Binomial}(n_i, p_i) \\
\mu_\alpha &amp;= \alpha + \alpha_{trt[i]} \\
\mu_\beta &amp;= \beta + \beta_{trt[i]} \\
\mathrm{logit}(p_i) &amp;= \mu_\beta (x_i - \mu_\alpha) \\
\alpha &amp;\sim \mathcal{N}(0, 0.06^2) \\
\alpha_{trt} &amp;\sim \mathcal{N}(0, \sigma_{trt}^2) \\
\sigma_{trt} &amp;\sim \textrm{to be defined}
\end{align*}\]</span></p>
<p>In the above model, <span class="math inline">\(\alpha\)</span> gets a fixed prior (the same as in the first iteration), and <span class="math inline">\(\alpha_{trt}\)</span> gets a Gaussian prior with an adaptive variance term that is allowed to be learned from the data. This notation is compact, but <span class="math inline">\(\alpha_{trt}\)</span> is actually two parameters - one each for pre- and post-adaptation block - but they both share the same variance term <span class="math inline">\(\sigma_{trt}\)</span>. This produces a <em>regularizing</em> effect where both treatment estimates are shrunk towards the mean, <span class="math inline">\(\alpha\)</span>.</p>
<p>I’ll discuss selecting a prior for the variance term shortly, but now I want to discuss setting the prior for the slope terms. Instead of modeling <span class="math inline">\(\beta\)</span> with a log-normal prior, I can sample from a normal distribution and take the exponential of it to produce a log-normal distribution. I.e.</p>
<p><span class="math display">\[
X \sim \mathcal{N}(3, 1^2) \\
Y = \exp\left\lbrace X \right\rbrace \Longleftrightarrow Y \sim \mathrm{Lognormal(3, 1^2)}
\]</span></p>
<p>The motivation behind this transformation is that it is now easier to include new slope variables as an additive affect. If both <span class="math inline">\(\beta\)</span> and <span class="math inline">\(\beta_{trt}\)</span> are specified with Gaussian priors, then the exponential of the sum will be a log-normal distribution! So now the model is</p>
<p><span class="math display">\[\begin{align*}
k_i &amp;\sim \mathrm{Binomial}(n_i, p_i) \\
\mu_\alpha &amp;= \alpha + \alpha_{trt[i]} \\
\mu_\beta &amp;= \beta + \beta_{trt[i]} \\
\mathrm{logit}(p_i) &amp;= \exp(\mu_\beta) (x_i - \mu_\alpha) \\
\alpha &amp;\sim \mathcal{N}(0, 0.06^2) \\
\alpha_{trt} &amp;\sim \mathcal{N}(0, \sigma_{trt}^2) \\
\beta &amp;\sim \mathcal{N}(3, 1^2) \\
\beta_{trt} &amp;\sim \mathcal{N}(0, \gamma_{trt}^2) \\
\sigma_{trt} &amp;\sim \textrm{to be defined} \\
\gamma_{trt} &amp;\sim \textrm{to be defined}
\end{align*}\]</span></p>
<p>Deciding on priors for the variance term requires some careful consideration. In one sense, the variance term is the within group variance, but with non-linear models like logistic regression, the logit link can have undesirable or unpredictable floor and ceiling effects. <span class="citation">Gelman and others (<a href="#ref-gelman2006prior" role="doc-biblioref">2006</a>)</span> recommends that for multilevel models with groups with less than say 5 levels to use a half Cauchy prior with a larger scale parameter. This weakly informative prior still has a regularizing affect and dissuades larger variance estimates. Even though the treatment group only has two levels, there is still value in specifying an adaptive prior for them, and there is also a lot of data for each treatment so partial pooling won’t make a difference anyway.</p>
<p><span class="math display">\[\begin{align*}
\sigma_{trt} &amp;\sim \mathrm{HalfCauchy}(0, 25) \\
\gamma_{trt} &amp;\sim \mathrm{HalfCauchy}(0, 25)
\end{align*}\]</span></p>
<p>Finally I can add in the age group level effects and specify the variance terms.</p>
<p><span class="math display">\[\begin{align*}
k_i &amp;\sim \mathrm{Binomial}(n_i, p_i) \\
\mu_\alpha &amp;= \alpha + \alpha_{trt[i]} + \alpha_{G[i]} \\
\mu_\beta &amp;= \beta + \beta_{trt[i]} + \beta_{G[i]} \\
\mathrm{logit}(p_i) &amp;= \exp(\mu_\beta) (x_i - \mu_\alpha) \\
\alpha &amp;\sim \mathcal{N}(0, 0.06^2) \\
\alpha_{trt} &amp;\sim \mathcal{N}(0, \sigma_{trt}^2) \\
\alpha_{G} &amp;\sim \mathcal{N}(0, \tau_{G}^2)\\
\beta &amp;\sim \mathcal{N}(3, 1^2) \\
\beta_{trt} &amp;\sim \mathcal{N}(0, \gamma_{trt}^2) \\
\beta_{G} &amp;\sim \mathcal{N}(0, \nu_{G}^2) \\
\sigma_{trt} &amp;\sim \mathrm{HalfCauchy}(0, 25) \\
\gamma_{trt} &amp;\sim \mathrm{HalfCauchy}(0, 25) \\
\tau_{G} &amp;\sim \mathrm{HalfCauchy}(0, 25) \\
\nu_{G} &amp;\sim \mathrm{HalfCauchy}(0, 25)
\end{align*}\]</span></p>
<p>Here is the corresponding Stan code that also computes the posterior retrodictions and JND and PSS estimates.</p>

<pre class="stan"><code>data {
  int N;
  int N_G;
  int N_T;
  int n[N];
  int k[N];
  vector[N] x;
  int G[N];
  int trt[N];
}
parameters {
  real a;
  real&lt;lower=machine_precision()&gt; sd_aG;
  real&lt;lower=machine_precision()&gt; sd_aT;
  real aG[N_G];
  real aT[N_T];

  real b;
  real&lt;lower=machine_precision()&gt; sd_bG;
  real&lt;lower=machine_precision()&gt; sd_bT;
  real bG[N_G];
  real bT[N_T];
}
model {
  vector[N] theta;

  a  ~ normal(0, 0.06);
  aG ~ normal(0, sd_aG);
  aT ~ normal(0, sd_aT);
  sd_aG ~ cauchy(0, 25);
  sd_aT ~ cauchy(0, 25);

  b  ~ normal(3.0, 1.0);
  bG ~ normal(0, sd_bG);
  bT ~ normal(0, sd_bT);
  sd_bG ~ cauchy(0, 25);
  sd_bT ~ cauchy(0, 25);

  for (i in 1:N) {
    real mu_a = a + aT[trt[i]] + aG[G[i]];
    real mu_b = b + bT[trt[i]] + bG[G[i]];
    theta[i] = exp(mu_b) * (x[i] - mu_a);
  }

  k ~ binomial_logit(n, theta);
}
generated quantities {
  matrix[N_G, N_T] pss;
  matrix[N_G, N_T] jnd;
  vector[N] k_pred;

  for (i in 1:N_G) {
    for (j in 1:N_T) {
      real mu_b = exp(b + bT[j] + bG[i]);
      real mu_a = a + aT[j] + aG[i];
      pss[i, j] = mu_a;
      jnd[i, j] = logit(0.84) / mu_b;
    }
  }
  
  for (i in 1:N) {
    real mu_a = a + aT[trt[i]] + aG[G[i]];
    real mu_b = b + bT[trt[i]] + bG[G[i]];
    real p = inv_logit(exp(mu_b) * (x[i] - mu_a));
    k_pred[i] = binomial_rng(n[i], p);
  }
}</code></pre>

<p><strong>Post-Model, Post-Data</strong></p>
<p><em>Fit Observed Data</em></p>
<p><em>Diagnose Posterior Fit</em></p>
<p><em>Posterior Retrodictive Checks</em></p>
</div>
<div id="iter3" class="section level2">
<h2><span class="header-section-number">3.3</span> Iteration 3 (the one for me)</h2>
<p><strong>Pre-Model, Pre-Data</strong></p>
<p><em>Conceptual Analysis</em></p>
<p><em>Define Observational Space</em></p>
<p><em>Construct Summary Statistics</em></p>
<p><strong>Post-Model, Pre-Data</strong></p>
<p><em>Develop Model</em></p>
<p><em>Construct Summary Functions</em></p>
<p><em>Simulate Bayesian Ensemble</em></p>
<p><em>Prior Checks</em></p>
<p><em>Configure Algorithm</em></p>
<p><em>Fit Simulated Ensemble</em></p>
<p><em>Algorithmic Calibration</em></p>
<p><em>Inferential Calibration</em></p>
<p><strong>Post-Model, Post-Data</strong></p>
<p><em>Fit Observed Data</em></p>
<p><em>Diagnose Posterior Fit</em></p>
<p><em>Posterior Retrodictive Checks</em></p>
</div>
<div id="iter4" class="section level2">
<h2><span class="header-section-number">3.4</span> Iteration 4 (what’s one more)</h2>
<p><strong>Pre-Model, Pre-Data</strong></p>
<p><em>Conceptual Analysis</em></p>
<p><em>Define Observational Space</em></p>
<p><em>Construct Summary Statistics</em></p>
<p><strong>Post-Model, Pre-Data</strong></p>
<p><em>Develop Model</em></p>
<p><em>Construct Summary Functions</em></p>
<p><em>Simulate Bayesian Ensemble</em></p>
<p><em>Prior Checks</em></p>
<p><em>Configure Algorithm</em></p>
<p><em>Fit Simulated Ensemble</em></p>
<p><em>Algorithmic Calibration</em></p>
<p><em>Inferential Calibration</em></p>
<p><strong>Post-Model, Post-Data</strong></p>
<p><em>Fit Observed Data</em></p>
<p><em>Diagnose Posterior Fit</em></p>
<p><em>Posterior Retrodictive Checks</em></p>
</div>
<div id="iter5" class="section level2">
<h2><span class="header-section-number">3.5</span> Iteration 5 (final_final_draft_2.pdf)</h2>
<p><strong>Pre-Model, Pre-Data</strong></p>
<p><em>Conceptual Analysis</em></p>
<p><em>Define Observational Space</em></p>
<p><em>Construct Summary Statistics</em></p>
<p><strong>Post-Model, Pre-Data</strong></p>
<p><em>Develop Model</em></p>
<p><em>Construct Summary Functions</em></p>
<p><em>Simulate Bayesian Ensemble</em></p>
<p><em>Prior Checks</em></p>
<p><em>Configure Algorithm</em></p>
<p><em>Fit Simulated Ensemble</em></p>
<p><em>Algorithmic Calibration</em></p>
<p><em>Inferential Calibration</em></p>
<p><strong>Post-Model, Post-Data</strong></p>
<p><em>Fit Observed Data</em></p>
<p><em>Diagnose Posterior Fit</em></p>
<p><em>Posterior Retrodictive Checks</em></p>
</div>
<div id="celebrate" class="section level2">
<h2><span class="header-section-number">3.6</span> Celebrate</h2>
<p><em>celebrate</em></p>

</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-betancourt2017conceptual">
<p>Betancourt, Michael. 2017. “A Conceptual Introduction to Hamiltonian Monte Carlo.” <em>arXiv Preprint arXiv: 1701.02434</em>.</p>
</div>
<div id="ref-betancourt2020">
<p>Betancourt, Michael. 2020. “Towards a Principled Bayesian Workflow.” <em>Betanalpha</em>. <a href="betanalpha.github.io">betanalpha.github.io</a>.</p>
</div>
<div id="ref-bolstad2016introduction">
<p>Bolstad, William M, and James M Curran. 2016. <em>Introduction to Bayesian Statistics</em>. John Wiley &amp; Sons.</p>
</div>
<div id="ref-R-rstanarm">
<p>Gabry, Jonah, and Ben Goodrich. 2020. <em>Rstanarm: Bayesian Applied Regression Modeling via Stan</em>. <a href="https://CRAN.R-project.org/package=rstanarm">https://CRAN.R-project.org/package=rstanarm</a>.</p>
</div>
<div id="ref-gelman2006data">
<p>Gelman, Andrew, and Jennifer Hill. 2006. <em>Data Analysis Using Regression and Multilevel/Hierarchical Models</em>. Cambridge university press.</p>
</div>
<div id="ref-gelman2006prior">
<p>Gelman, Andrew, and others. 2006. “Prior Distributions for Variance Parameters in Hierarchical Models (Comment on Article by Browne and Draper).” <em>Bayesian Analysis</em> 1 (3): 515–34.</p>
</div>
<div id="ref-R-arm">
<p>Gelman, Andrew, and Yu-Sung Su. 2020. <em>Arm: Data Analysis Using Regression and Multilevel/Hierarchical Models</em>. <a href="https://CRAN.R-project.org/package=arm">https://CRAN.R-project.org/package=arm</a>.</p>
</div>
<div id="ref-gilks1992adaptive">
<p>Gilks, Walter R, and Pascal Wild. 1992. “Adaptive Rejection Sampling for Gibbs Sampling.” <em>Journal of the Royal Statistical Society: Series C (Applied Statistics)</em> 41 (2): 337–48.</p>
</div>
<div id="ref-R-rstan">
<p>Guo, Jiqiang, Jonah Gabry, Ben Goodrich, and Sebastian Weber. 2020. <em>Rstan: R Interface to Stan</em>. <a href="https://CRAN.R-project.org/package=rstan">https://CRAN.R-project.org/package=rstan</a>.</p>
</div>
<div id="ref-leimkuhler2004simulating">
<p>Leimkuhler, Benedict, and Sebastian Reich. 2004. <em>Simulating Hamiltonian Dynamics</em>. Vol. 14. Cambridge university press.</p>
</div>
<div id="ref-neal2003slice">
<p>Neal, Radford M. 2003. “Slice Sampling.” <em>Annals of Statistics</em>, 705–41.</p>
</div>
<div id="ref-vatakis2007influence">
<p>Vatakis, Argiro, Linda Bayliss, Massimiliano Zampini, and Charles Spence. 2007. “The Influence of Synchronous Audiovisual Distractors on Audiovisual Temporal Order Judgments.” <em>Perception &amp; Psychophysics</em> 69 (2): 298–309.</p>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="6">
<li id="fn6"><p>The opposite of a Frequentist.<a href="workflow.html#fnref6" class="footnote-back">↩︎</a></p></li>
<li id="fn7"><p>Efficiency of a sampler is related to the proportion of proposal samples that get accepted.<a href="workflow.html#fnref7" class="footnote-back">↩︎</a></p></li>
<li id="fn8"><p>Factor variables also go by the name index variable or categorical variable<a href="workflow.html#fnref8" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="motivating-data.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="model-checking.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": false,
"twitter": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": null,
"history": {
"link": null,
"text": null
},
"view": {
"link": "https://github.com/adknudson/thesis/blob/master/030-workflow.Rmd",
"text": null
},
"download": ["adknudson-thesis.pdf"],
"toc": {
"collapse": "section",
"scroll_highlight": true
},
"toc_depth": 3,
"toolbar": {
"position": "fixed"
},
"search": true,
"info": true
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
