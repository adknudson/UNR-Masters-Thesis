```{r ch5_4-setup, include=FALSE}
library(FangPsychometric)
library(dplyr)
library(rstan)

options(mc.cores = parallel::detectCores())
rstan_options(auto_write = TRUE)

av_dat <- audiovisual_binomial %>%
  filter(trial %in% c("pre", "post1"),
         rid != "av-post1-O-f-CE") %>%
  mutate(trt = droplevels(trial),
         sid = droplevels(sid))
```


## Iteration 3 (The one for Me)

### Model Development

```{stan output.var="fit_obs_iter3"}
functions {
  real inv_Psi(real p, real a, real b, real l) {
    return logit((p - l) / (1 - 2 * l)) / b + a;
  }
}
data {
  int N;
  int N_G;
  int N_T;
  int N_S;
  int n[N];
  int k[N];
  vector[N] x;
  int G[N];
  int trt[N];
  int S[N];
}
parameters {
  real a;
  real<lower=0> sd_aG;
  real<lower=0> sd_aT;
  real<lower=0> sd_aS;
  real aG[N_G];
  real aT[N_T];
  real aS[N_S];
  
  real b;
  real<lower=0> sd_bG;
  real<lower=0> sd_bT;
  real<lower=0> sd_bS;
  real bG[N_G];
  real bT[N_T];
  real bS[N_S];
  
  real<lower=0,upper=1> l;
}
model {
  vector[N] theta;

  a  ~ normal(0, 0.05);
  aG ~ normal(0, sd_aG);
  aT ~ normal(0, sd_aT);
  aS ~ normal(0, sd_aS);
  sd_aG ~ cauchy(2.5, 2.5);
  sd_aT ~ cauchy(2.5, 2.5);
  sd_aS ~ cauchy(2.5, 2.5);
  
  b  ~ normal(2.5, 1.0);
  bG ~ normal(0, sd_bG);
  bT ~ normal(0, sd_bT);
  bS ~ normal(0, sd_bS);
  sd_bG ~ cauchy(2.5, 2.5);
  sd_bT ~ cauchy(2.5, 2.5);
  sd_bS ~ cauchy(2.5, 2.5);
  
  l ~ beta(4, 96);
  
  for (i in 1:N) {
    real mu_b = exp(b + bG[G[i]] + bT[trt[i]] + bS[S[i]]);
    real mu_a = a + aG[G[i]] + aT[trt[i]] + aS[S[i]];
    theta[i] = l + (1 - 2*l) * inv_logit(mu_b * (x[i] - mu_a));
  }
  
  k ~ binomial(n, theta);
}
generated quantities {
  int y_post_pred[N];
  matrix[N_G, N_T] pss;
  matrix[N_G, N_T] jnd;
  
  for (i in 1:N_G) {
    for (j in 1:N_T) {
      real mu_b = exp(b + bG[i] + bT[j]);
      real mu_a = a + aG[i] + aT[j];
      pss[i, j] = inv_Psi(0.50, mu_a, mu_b, l);
      jnd[i, j] = inv_Psi(0.84, mu_a, mu_b, l) - inv_Psi(0.50, mu_a, mu_b, l);
    }
  }

  for (i in 1:N) {
    real mu_b = exp(b + bG[G[i]] + bT[trt[i]] + bS[S[i]]);
    real mu_a = a + aG[G[i]] + aT[trt[i]] + aS[S[i]];
    real theta = l + (1 - 2*l) * inv_logit(mu_b * (x[i] - mu_a));
    y_post_pred[i] = binomial_rng(n[i], theta);
  }
}
```




```{r}
obs_dat3 <- list(N = nrow(av_dat),
                 N_G = max(as.integer(av_dat$age_group)),
                 N_T = max(as.integer(av_dat$trt)),
                 N_S = max(as.integer(av_dat$sid)),
                 x = av_dat$soa / 1000,
                 k = av_dat$k,
                 n = av_dat$n,
                 G = as.integer(av_dat$age_group),
                 trt = as.integer(av_dat$trt),
                 S = as.integer(av_dat$sid))

m3_fit <- sampling(fit_obs_iter3, data = obs_dat3, 
                   iter = 7500, warmup = 2500, refresh = 100,
                   chains = 6,
                   control = list(adapt_delta=0.95, max_treedepth=12))
```


### Diagnose posterior fit

```{r}
check_hmc_diagnostics(m3_fit)
```

### Posterior retrodictive checks

```{r}
post <- extract(m3_fit)
summ <- summary(m3_fit)$summary
```

```{r}
post_k_pred <- t(apply(post$y_post_pred, 2, quantile,
                          probs = c(1.5, 5.5, 50, 94.5, 98.5) / 100))

pred <- cbind(post_k_pred, post_mean = colMeans(post$y_post_pred)) %>%
  sweep(1, obs_dat3$n, FUN = "/") %>%
  bind_cols(obs_dat3) %>%
  select(-N) %>%
  mutate(p = k / n)

print(pred, n = 21)
```


```{r}
pred %>%
  ggplot(aes(x, p)) +
  geom_jitter(width = 0.0125, col = rgb(123, 28, 212, maxColorValue = 255)) +
  geom_jitter(aes(y = `50%`), col = rgb(28, 214, 68, 120, maxColorValue = 255),
              width = 0.0125) +
  facet_grid(G~trt)
```

```{stan output.var="fit_obs_iter4"}
functions {
  real inv_Psi(real p, real a, real b, real l) {
    return logit((p - l) / (1 - 2 * l)) / b + a;
  }
}
data {
  int N;
  int N_G;
  int N_T;
  int N_S;
  int n[N];
  int k[N];
  vector[N] x;
  int G[N];
  int trt[N];
  int S[N];
}
parameters {
  real a;
  real<lower=0> sd_aG;
  real<lower=0> sd_aT;
  real<lower=0> sd_aS;
  real aG[N_G];
  real aT[N_T];
  real aS[N_S];
  
  real b;
  real<lower=0> sd_bG;
  real<lower=0> sd_bT;
  real<lower=0> sd_bS;
  real bG[N_G];
  real bT[N_T];
  real bS[N_S];
  
  real<lower=0,upper=1> l;
  real lG[N_G];
}
model {
  vector[N] theta;

  a  ~ normal(0, 0.05);
  aG ~ normal(0, sd_aG);
  aT ~ normal(0, sd_aT);
  aS ~ normal(0, sd_aS);
  sd_aG ~ cauchy(2.5, 2.5);
  sd_aT ~ cauchy(2.5, 2.5);
  sd_aS ~ cauchy(2.5, 2.5);
  
  b  ~ normal(2.5, 1.0);
  bG ~ normal(0, sd_bG);
  bT ~ normal(0, sd_bT);
  bS ~ normal(0, sd_bS);
  sd_bG ~ cauchy(2.5, 2.5);
  sd_bT ~ cauchy(2.5, 2.5);
  sd_bS ~ cauchy(2.5, 2.5);
  
  l ~ beta(4, 96);
  lG ~ normal(0, 0.005);
  
  for (i in 1:N) {
    real mu_b = exp(b + bG[G[i]] + bT[trt[i]] + bS[S[i]]);
    real mu_a = a + aG[G[i]] + aT[trt[i]] + aS[S[i]];
    real mu_l = l + lG[G[i]];
    theta[i] = mu_l + (1 - 2*mu_l) * inv_logit(mu_b * (x[i] - mu_a));
  }
  
  k ~ binomial(n, theta);
}
generated quantities {
  int y_post_pred[N];
  matrix[N_G, N_T] pss;
  matrix[N_G, N_T] jnd;
  
  for (i in 1:N_G) {
    for (j in 1:N_T) {
      real mu_b = exp(b + bG[i] + bT[j]);
      real mu_a = a + aG[i] + aT[j];
      real mu_l = l + lG[G[i]];
      pss[i, j] = inv_Psi(0.50, mu_a, mu_b, mu_l);
      jnd[i, j] = inv_Psi(0.84, mu_a, mu_b, mu_l) - inv_Psi(0.50, mu_a, mu_b, mu_l);
    }
  }

  for (i in 1:N) {
    real mu_b = exp(b + bG[G[i]] + bT[trt[i]] + bS[S[i]]);
    real mu_a = a + aG[G[i]] + aT[trt[i]] + aS[S[i]];
    real mu_l = l + lG[G[i]];
    real theta = mu_l + (1 - 2*mu_l) * inv_logit(mu_b * (x[i] - mu_a));
    y_post_pred[i] = binomial_rng(n[i], theta);
  }
}
```




```{r}
m4_fit <- sampling(fit_obs_iter4, data = obs_dat3, 
                   iter = 7500, warmup = 2500, refresh = 100,
                   chains = 6,
                   control = list(adapt_delta=0.95, max_treedepth=12))

check_hmc_diagnostics(m4_fit)
```

### Posterior retrodictive checks

```{r}
post <- extract(m4_fit)
```

```{r}
post_k_pred <- t(apply(post$y_post_pred, 2, quantile,
                          probs = c(1.5, 5.5, 50, 94.5, 98.5) / 100))

pred <- cbind(post_k_pred, post_mean = colMeans(post$y_post_pred)) %>%
  sweep(1, obs_dat3$n, FUN = "/") %>%
  bind_cols(obs_dat3) %>%
  select(-N) %>%
  mutate(p = k / n)

print(pred, n = 21)
```


```{r}
pred %>%
  ggplot(aes(x, p)) +
  geom_jitter(width = 0.0125, col = rgb(123, 28, 212, maxColorValue = 255)) +
  geom_jitter(aes(y = `50%`), col = rgb(28, 214, 68, 120, maxColorValue = 255),
              width = 0.0125) +
  facet_grid(G~trt)
```
